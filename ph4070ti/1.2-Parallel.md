# Parallel loop, managed
## Code
```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  
    // For each output feature map
    #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
      #pragma acc loop 
      for (int j = 0; j < l->out_height; j++) {
        #pragma acc loop 
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); 
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum) 
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); 
                int x_j = -l->padding + j * l->stride + f_j; 
                int x_i = -l->padding + i * l->stride + f_i; 
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
```

## Minfo
```
$ make
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
conv_forward:
     46, Generating NVIDIA GPU code
         50, #pragma acc loop gang /* blockIdx.x */
         52, #pragma acc loop seq
         54, #pragma acc loop seq
         59, #pragma acc loop seq
         60, #pragma acc loop seq
         61, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     46, Generating implicit copyin(l) [if not already present]
         Generating implicit copy(Y[:]) [if not already present]
         Generating implicit copyin(X[:]) [if not already present]
     52, Loop is parallelizable
     54, Loop is parallelizable
     59, Loop is parallelizable
     60, Loop is parallelizable
     61, Loop is parallelizable
pool_forward:
    152, Zero trip check eliminated
fc_forward:
    207, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

## Execution
```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.274524 seconds
Create Network time:0.000273 seconds
Load Network Parameters time:0.003308 seconds
Create Ouputs time:0.000265 seconds

Net Forward total time:157.350234 seconds
    Time for conv1: 71.677875 seconds
    Time for relu1: 2.804403 seconds
    Time for pool1: 1.883093 seconds
    Time for conv2: 52.614324 seconds
    Time for relu2: 4.805726 seconds
    Time for pool2: 2.106152 seconds
    Time for conv3: 19.099938 seconds
    Time for relu3: 2.149285 seconds
    Time for pool3: 0.054824 seconds
    Time for fc: 0.132830 seconds
    Time for softmax: 0.009186 seconds

  Conv: 143.392137 seconds
  ReLU: 9.759414 seconds
  Pool: 4.044069 seconds
  FC:   0.132830 seconds
  Softmax: 0.009186 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000275 seconds
Free memory time:0.016539 seconds
Total time:157.645419 seconds
```

## nc_acc

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.275059 seconds
Create Network time:0.000319 seconds
Load Network Parameters time:0.003305 seconds
Create Ouputs time:0.000279 seconds

Net Forward total time:158.709261 seconds
    Time for conv1: 72.090187 seconds
    Time for relu1: 2.848683 seconds
    Time for pool1: 1.884967 seconds
    Time for conv2: 53.070161 seconds
    Time for relu2: 4.838615 seconds
    Time for pool2: 2.107968 seconds
    Time for conv3: 19.464122 seconds
    Time for relu3: 2.193207 seconds
    Time for pool3: 0.055201 seconds
    Time for fc: 0.132765 seconds
    Time for softmax: 0.009326 seconds

  Conv: 144.624470 seconds
  ReLU: 9.880504 seconds
  Pool: 4.048136 seconds
  FC:   0.132765 seconds
  Softmax: 0.009326 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000279 seconds
Free memory time:0.016703 seconds
Total time:159.005205 seconds
END!

Accelerator Kernel Timing data
/home/gskondras/cifar/cnn-cifar10_0/1.2-Parallel/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 142,452,990
    46: compute region reached 150000 times
        46: kernel launched 150000 times
            grid: [1024]  block: [128]
             device time(us): total=142,452,990 max=2,101 min=345 avg=949
            elapsed time(us): total=144,165,762 max=2,112 min=355 avg=961
    46: data region reached 300000 times
```