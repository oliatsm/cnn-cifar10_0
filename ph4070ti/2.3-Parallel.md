# Parallel loop, managed
## Code
```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  
    // For each output feature map
    #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
      #pragma acc loop 
      for (int j = 0; j < l->out_height; j++) {
        #pragma acc loop 
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); 
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum) 
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); 
                int x_j = -l->padding + j * l->stride + f_j; 
                int x_i = -l->padding + i * l->stride + f_i; 
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
```

## Minfo
```
$ make
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
conv_forward:
     46, Generating NVIDIA GPU code
         50, #pragma acc loop gang /* blockIdx.x */
         52, #pragma acc loop seq
         54, #pragma acc loop seq
         59, #pragma acc loop seq
         60, #pragma acc loop seq
         61, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     46, Generating implicit copyin(l) [if not already present]
         Generating implicit copy(Y[:]) [if not already present]
         Generating implicit copyin(X[:]) [if not already present]
     52, Loop is parallelizable
     54, Loop is parallelizable
     59, Loop is parallelizable
     60, Loop is parallelizable
     61, Loop is parallelizable
pool_forward:
    152, Zero trip check eliminated
fc_forward:
    207, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

## Execution
```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Load Data time:0.276452 seconds
Create Network time:0.000337 seconds
Load Network Parameters time:0.003297 seconds
Create Ouputs time:0.000288 seconds

Net Forward total time:157.851853 seconds
    Time for conv1: 71.905290 seconds
    Time for relu1: 2.798518 seconds
    Time for pool1: 1.881958 seconds
    Time for conv2: 52.789905 seconds
    Time for relu2: 4.793857 seconds
    Time for pool2: 2.103715 seconds
    Time for conv3: 19.230628 seconds
    Time for relu3: 2.142099 seconds
    Time for pool3: 0.054728 seconds
    Time for fc: 0.132637 seconds
    Time for softmax: 0.005834 seconds

  Conv: 143.925823 seconds
  ReLU: 9.734475 seconds
  Pool: 4.040400 seconds
  FC:   0.132637 seconds
  Softmax: 0.005834 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000272 seconds
Free memory time:0.016297 seconds
Total time:158.148797 seconds
```