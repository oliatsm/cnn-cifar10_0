# Parallel Data, Padding
## Code
```c
60: void pad_input(float* restrict X, Conv_Layer* l) {
#pragma acc parallel loop present(X,l)
  for ( int c = 0; c < l->in_depth; c++) {
    #pragma acc loop
    for (int j = 0; j < l->in_height; j++) {
      #pragma acc loop
      for (int i = 0; i < l->in_width; i++) {
        int padded_idx = (j + l->padding) * l->padded_width + (i + l->padding) + c * l->padded_height * l->padded_width;
        int in_idx = j * l->in_width + i + c * l->in_height * l->in_width;
        l->in_padded[padded_idx] = X[in_idx];
      }
    }
  }
}


// Performs the forward pass for a convolutional layer.
// X: Input data, l: Convolutional layer, Y: Output data
78: void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {

  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) present(l) copyout(Y[0:l->out_size])
{
    pad_input(X, l); //Create input with zero-padding
   // For each output feature map
#pragma acc parallel loop  
    for ( int m = 0; m < l->out_depth; m++) {
      #pragma acc loop
      for (int j = 0; j < l->out_height; j++) {
       #pragma acc loop
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); 
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
        #pragma acc loop  reduction(+:sum) 
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                ...
```

## Minfo
```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     60, Generating present(l[:],X[:])
         Generating NVIDIA GPU code
         62, #pragma acc loop gang /* blockIdx.x */
         64, #pragma acc loop seq
         66, #pragma acc loop vector(128) /* threadIdx.x */
     64, Loop is parallelizable
     66, Loop is parallelizable
conv_forward:
     82, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating copyin(X[:in_size]) [if not already present]
     83, Generating NVIDIA GPU code
         86, #pragma acc loop gang /* blockIdx.x */
         88, #pragma acc loop seq
         90, #pragma acc loop seq
         95, #pragma acc loop seq
         96, #pragma acc loop seq
         97, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     88, Loop is parallelizable
     90, Loop is parallelizable
     95, Loop is parallelizable
     96, Loop is parallelizable
     97, Loop is parallelizable
    102, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    185, Zero trip check eliminated
fc_forward:
    240, FMA (fused multiply-add) instruction(s) generated
load_conv:
    302, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

## Execution

```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Load Data time:0.390018 seconds
Create Network time:0.123133 seconds
Load Network Parameters time:0.003375 seconds
Create Ouputs time:0.000170 seconds

Net Forward total time:93.543965 seconds
    Time for conv1: 50.563866 seconds
    Time for relu1: 0.226810 seconds
    Time for pool1: 0.573387 seconds
    Time for conv2: 31.374860 seconds
    Time for relu2: 0.078262 seconds
    Time for pool2: 0.188051 seconds
    Time for conv3: 10.317742 seconds
    Time for relu3: 0.029737 seconds
    Time for pool3: 0.048366 seconds
    Time for fc: 0.123772 seconds
    Time for softmax: 0.006580 seconds

  Conv: 92.256468 seconds
  ReLU: 0.334809 seconds
  Pool: 0.809804 seconds
  FC:   0.123772 seconds
  Softmax: 0.006580 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000283 seconds
Free memory time:0.037835 seconds
Total time:94.098779 seconds
```

## Profiling
### nv_time
```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.385766 seconds
Create Network time:0.135556 seconds
Load Network Parameters time:0.003403 seconds
Create Ouputs time:0.000170 seconds

Net Forward total time:97.300599 seconds
    Time for conv1: 51.852827 seconds
    Time for relu1: 0.215578 seconds
    Time for pool1: 0.576631 seconds
    Time for conv2: 32.617770 seconds
    Time for relu2: 0.077195 seconds
    Time for pool2: 0.187920 seconds
    Time for conv3: 11.552741 seconds
    Time for relu3: 0.028445 seconds
    Time for pool3: 0.048891 seconds
    Time for fc: 0.123662 seconds
    Time for softmax: 0.006421 seconds

  Conv: 96.023338 seconds
  ReLU: 0.321218 seconds
  Pool: 0.813442 seconds
  FC:   0.123662 seconds
  Softmax: 0.006421 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000260 seconds
Free memory time:0.037805 seconds
Total time:97.863558 seconds
END!

Accelerator Kernel Timing data
/home/gskondras/cifar/cnn-cifar10_0/2.2-Data-pad/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 59
    42: data region reached 9 times
        42: data copyin transfers: 15
             device time(us): total=59 max=9 min=2 avg=3
/home/gskondras/cifar/cnn-cifar10_0/2.2-Data-pad/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 25
    53: data region reached 9 times
        53: data copyin transfers: 9
             device time(us): total=25 max=6 min=2 avg=2
/home/gskondras/cifar/cnn-cifar10_0/2.2-Data-pad/layers.c
  pad_input  NVIDIA  devicenum=0
    time(us): 350,001
    60: compute region reached 150000 times
        60: kernel launched 150000 times
            grid: [1024]  block: [128]
             device time(us): total=350,001 max=3 min=2 avg=2
            elapsed time(us): total=1,915,199 max=452 min=11 avg=12
    60: data region reached 300000 times
/home/gskondras/cifar/cnn-cifar10_0/2.2-Data-pad/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 89,200,126
    82: data region reached 300000 times
        82: data copyin transfers: 150000
             device time(us): total=719,497 max=18 min=3 avg=4
        111: data copyout transfers: 150000
             device time(us): total=1,160,124 max=27 min=3 avg=7
    83: compute region reached 150000 times
        83: kernel launched 150000 times
            grid: [1024]  block: [128]
             device time(us): total=87,320,505 max=1,017 min=181 avg=582
            elapsed time(us): total=88,767,934 max=1,030 min=190 avg=591
/home/gskondras/cifar/cnn-cifar10_0/2.2-Data-pad/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 30
    302: update directive reached 3 times
        302: data copyin transfers: 6
             device time(us): total=30 max=10 min=2 avg=5
```

### nsys
**GPU Contexts** 99.184 s
#### Kernel Summary

Time	Total Time	Instances	Avg	         Med	        Min	      Max	     StdDev	      Name
99.7%	 87.265 s	  150000	581.768 μs	594.916 μs	180.545 μs	1.017 ms	322.220 μs	conv_forward_83_gpu
 0.3%	255.604 ms	150000	  1.704 μs	  1.568 μs	  1.344 μs	2.784 μs	    341 ns  pad_input_60_gpu

#### Memory Time
Time	Total Time	Count	Avg	Med	Min	Max	StdDev	Operation
75.4%	725.023 ms	150000	4.833 μs	3.296 μs	896 ns	10.784 μs	3.878 μs	[CUDA memcpy Device-to-Host]
24.6%	237.043 ms	150030	1.580 μs	1.824 μs	256 ns	7.456 μs	862 ns	[CUDA memcpy Host-to-Device]