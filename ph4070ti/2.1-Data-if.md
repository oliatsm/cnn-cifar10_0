# Parallel, data on device, if

## Code
```c
Conv_Layer* make_conv_layer(int W, int H, int D, int K, int M, int S, int P) {
  // Allocate memory for the convolutional layer struct
//   ...
  // Allocate memory for weights and bias arrays
  layer->weights = malloc(sizeof(float) * K * K * M * D);
  layer->bias = malloc(sizeof(float) * M);
  #pragma acc enter data copyin(layer[0:1])
  #pragma acc enter data create(layer->weights[0:layer->weights_size],layer->bias[0:M])

  return layer;
}

void free_conv(Conv_Layer* l) {
#pragma acc exit data delete(l->weights[0:l->weights_size],l->bias[0:l->out_depth])
#pragma acc exit data delete(l[0:1])
  free(l->bias);
  free(l->weights);
  free(l);
}

void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  
  int in_size = l->in_width*l->in_height*l->in_depth;
    // For each output feature map
  #pragma acc data copyin(X[0:in_size]) present(l) copyout(Y[0:l->out_size])
{
  #pragma acc parallel loop 
    for (int m = 0; m < l->out_depth; m++) {
      #pragma acc loop 
      for (int j = 0; j < l->out_height; j++) {
        #pragma acc loop 
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); 
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum) 
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); 
                int x_j = -l->padding + j * l->stride + f_j; 
                int x_i = -l->padding + i * l->stride + f_i; 
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
...

}

int load_conv(Conv_Layer* l, char* file_name) {
  int filter_width, filter_height, depth, filters;

  FILE* fin = fopen(file_name, "r");
  if (fin == NULL) {
...
  fclose(fin);
  #pragma acc update device (l->weights[0:l->weights_size],l->bias[0:l->out_depth])
  return 0;
}

                
```

## Minfo
```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c main.c -o main.o
arr2txt:
    332, Zero trip check eliminated
arr2txt_2:
    354, Zero trip check eliminated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     35, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size],layer->bias[:M])
free_conv:
     43, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->weights_size])
conv_forward:
     55, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating copyin(X[:in_size]) [if not already present]
         Generating NVIDIA GPU code
         57, #pragma acc loop gang /* blockIdx.x */
         59, #pragma acc loop seq
         61, #pragma acc loop seq
         66, #pragma acc loop seq
         67, #pragma acc loop seq
         68, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     59, Loop is parallelizable
     61, Loop is parallelizable
     66, Loop is parallelizable
     67, Loop is parallelizable
     68, Loop is parallelizable
     75, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    160, Zero trip check eliminated
fc_forward:
    215, FMA (fused multiply-add) instruction(s) generated
load_conv:
    274, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

## Execution

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Load Data time:0.380226 seconds
Create Network time:0.123857 seconds
Load Network Parameters time:0.003367 seconds
Create Ouputs time:0.000167 seconds

Net Forward total time: 134.977371 seconds
    Time for conv1: 66.393344 seconds
    Time for relu1: 0.221483 seconds
    Time for pool1: 0.574898 seconds
    Time for conv2: 51.249155 seconds
    Time for relu2: 0.082670 seconds
    Time for pool2: 0.188781 seconds
    Time for conv3: 16.044667 seconds
    Time for relu3: 0.030892 seconds
    Time for pool3: 0.048365 seconds
    Time for fc: 0.123386 seconds
    Time for softmax: 0.007267 seconds

  Conv: 133.687166 seconds
  ReLU: 0.335045 seconds
  Pool: 0.812044 seconds
    FC: 0.123386 seconds
  Softmax: 0.007267 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000272 seconds
Free memory time:0.035837 seconds
Total time:135.521096 seconds
```

## nc_acc

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Load Data time:0.380620 seconds
Create Network time:0.128433 seconds
Load Network Parameters time:0.003385 seconds
Create Ouputs time:0.000166 seconds

Net Forward total time: 137.740369 seconds
    Time for conv1: 67.324307 seconds
    Time for relu1: 0.216468 seconds
    Time for pool1: 0.575896 seconds
    Time for conv2: 52.157572 seconds
    Time for relu2: 0.073730 seconds
    Time for pool2: 0.189021 seconds
    Time for conv3: 16.980785 seconds
    Time for relu3: 0.028150 seconds
    Time for pool3: 0.050856 seconds
    Time for fc: 0.124135 seconds
    Time for softmax: 0.006966 seconds

  Conv: 136.462664 seconds
  ReLU: 0.318348 seconds
  Pool: 0.815773 seconds
    FC: 0.124135 seconds
  Softmax: 0.006966 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000272 seconds
Free memory time:0.036520 seconds
Total time:138.289765 seconds
END!

Accelerator Kernel Timing data
/home/gskondras/cifar/cnn-cifar10_0/2.1-Data-if/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 37
    35: data region reached 6 times
        35: data copyin transfers: 9
             device time(us): total=37 max=10 min=2 avg=4
/home/gskondras/cifar/cnn-cifar10_0/2.1-Data-if/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 24
    43: data region reached 6 times
        43: data copyin transfers: 6
             device time(us): total=24 max=6 min=3 avg=4
/home/gskondras/cifar/cnn-cifar10_0/2.1-Data-if/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 131,411,699
    55: compute region reached 150000 times
        55: kernel launched 150000 times
            grid: [1024]  block: [128]
             device time(us): total=129,394,615 max=1,352 min=299 avg=862
            elapsed time(us): total=131,135,304 max=1,383 min=309 avg=874
    55: data region reached 300000 times
        55: data copyin transfers: 150000
             device time(us): total=789,081 max=19 min=3 avg=5
        85: data copyout transfers: 150000
             device time(us): total=1,228,003 max=23 min=3 avg=8
/home/gskondras/cifar/cnn-cifar10_0/2.1-Data-if/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 27
    274: update directive reached 3 times
        274: data copyin transfers: 6
             device time(us): total=27 max=9 min=2 avg=4
```