# Parallel loop optimization

## Parallel, Data transfer, Padding, 1200 images

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c main.c -o main.o
arr2txt:
    332, Zero trip check eliminated
arr2txt_2:
    354, Zero trip check eliminated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang /* blockIdx.x */
         86, #pragma acc loop seq
         88, #pragma acc loop seq
         93, #pragma acc loop seq
         94, #pragma acc loop seq
         95, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     86, Loop is parallelizable
     88, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     95, Loop is parallelizable
    100, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    183, Zero trip check eliminated
fc_forward:
    238, FMA (fused multiply-add) instruction(s) generated
load_conv:
    296, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-pad$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022973 seconds
Create Network time:0.200192 seconds
Load Network Parameters time:0.008106 seconds
Create Ouputs time:0.000034 seconds

Net Forward total time:3.811845 seconds
    Time for conv1: 2.017275 seconds
    Time for relu1: 0.010927 seconds
    Time for pool1: 0.047185 seconds
    Time for conv2: 1.287133 seconds
    Time for relu2: 0.003591 seconds
    Time for pool2: 0.015295 seconds
    Time for conv3: 0.419812 seconds
    Time for relu3: 0.001052 seconds
    Time for pool3: 0.003869 seconds
    Time for fc: 0.005046 seconds
    Time for softmax: 0.000310 seconds

  Conv: 3.724221 seconds
  ReLU: 0.015571 seconds
  Pool: 0.066350 seconds
  FC:   0.005046 seconds
  Softmax: 0.000310 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000019 seconds
Free memory time:0.001512 seconds
Total time:4.044680 seconds
END!
```
## Parallel with loop optimizations

```c
File: layers.c
059: // Add zero-padding to input data of conv_layer l
060: void pad_input(float* restrict X, Conv_Layer* l) {
061:   int in_size = l->in_width * l->in_height * l->in_depth;
062: #pragma acc parallel loop present(l) copyin(X[0:in_size]) gang
063:   for (int c = 0; c < l->in_depth; c++) {
064:   #pragma acc loop 
065:     for (int j = 0; j < l->in_height; j++) {
066:     #pragma acc loop vector
067:       for (int i = 0; i < l->in_width; i++) {

079: void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
080:   pad_input(X, l); //Create input with zero-padding
081: 
082:   // For each output feature map
083: #pragma acc parallel loop present(l) copyout(Y[0:l->out_size]) gang collapse(2)
084:   for (int m = 0; m < l->out_depth; m++) {
085:     for (int j = 0; j < l->out_height; j++) {
086:     #pragma acc loop worker
087:       for (int i = 0; i < l->out_width; i++) {
088:         int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
089:         // Calculate dot product of Weights*Input
090:         float sum = 0.0f;
091:       #pragma acc loop reduction(+:sum) vector
092:         for (int c = 0; c < l->in_depth; c++) {
093:           for (int f_j = 0; f_j < l->filter_width; f_j++) {
094:             for (int f_i = 0; f_i < l->filter_width; f_i++) {

```

```
$ make 
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang collapse(2) /* blockIdx.x */
         85,   /* blockIdx.x collapsed */
         87, #pragma acc loop worker(4) /* threadIdx.y */
         92, #pragma acc loop vector(32) /* threadIdx.x */
             Generating reduction(+:sum)
         93, #pragma acc loop seq
         94, #pragma acc loop seq
        101, Vector barrier inserted for vector loop reduction
     87, Loop is parallelizable
     92, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     99, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    182, Zero trip check eliminated
fc_forward:
    237, FMA (fused multiply-add) instruction(s) generated
load_conv:
    295, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

### 1200 images

```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.021844 seconds
Create Network time:0.199221 seconds
Load Network Parameters time:0.008019 seconds
Create Ouputs time:0.000050 seconds

Net Forward total time:0.351460 seconds
    Time for conv1: 0.113322 seconds
    Time for relu1: 0.010505 seconds
    Time for pool1: 0.046259 seconds
    Time for conv2: 0.091559 seconds
    Time for relu2: 0.003487 seconds
    Time for pool2: 0.014754 seconds
    Time for conv3: 0.061264 seconds
    Time for relu3: 0.000920 seconds
    Time for pool3: 0.003781 seconds
    Time for fc: 0.005003 seconds
    Time for softmax: 0.000274 seconds

  Conv: 0.266145 seconds
  ReLU: 0.014913 seconds
  Pool: 0.064794 seconds
  FC:   0.005003 seconds
  Softmax: 0.000274 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000028 seconds
Free memory time:0.001385 seconds
Total time:0.582008 seconds
END!
```

#### nvprof
```
$ nvprof ./cnn-cifar10-profile 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.019945 seconds
==985236== NVPROF is profiling process 985236, command: ./cnn-cifar10-profile
Create Network time:0.455102 seconds
Load Network Parameters time:0.008017 seconds
Create Ouputs time:0.000032 seconds

Net Forward total time:0.460521 seconds
    Time for conv1: 0.151812 seconds
    Time for relu1: 0.015372 seconds
    Time for pool1: 0.038007 seconds
    Time for conv2: 0.129119 seconds
    Time for relu2: 0.004992 seconds
    Time for pool2: 0.012312 seconds
    Time for conv3: 0.098159 seconds
    Time for relu3: 0.001308 seconds
    Time for pool3: 0.003219 seconds
    Time for fc: 0.005325 seconds
    Time for softmax: 0.000325 seconds

  Conv: 0.379089 seconds
  ReLU: 0.021672 seconds
  Pool: 0.053537 seconds
  FC:   0.005325 seconds
  Softmax: 0.000325 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000032 seconds
Free memory time:0.001263 seconds
Total time:0.944911 seconds
END!
==985236== Profiling application: ./cnn-cifar10-profile
==985236== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   75.65%  97.084ms      3600  26.967us  12.288us  39.360us  _8layers_c_conv_forward_80_gpu
                    9.69%  12.437ms      3600  3.4540us  3.2310us  12.576us  _8layers_c_pad_input_61_gpu
                    8.85%  11.361ms      3600  3.1550us  1.4390us  18.495us  [CUDA memcpy DtoH]
                    5.80%  7.4454ms      3630  2.0510us     736ns  5.7610us  [CUDA memcpy HtoD]
      API calls:   34.49%  159.38ms     18012  8.8480us  1.0510us  751.38us  cuStreamSynchronize
                   28.43%  131.40ms         1  131.40ms  131.40ms  131.40ms  cuDevicePrimaryCtxRetain
                   13.75%  63.562ms      3600  17.656us  11.109us  97.417us  cuMemcpyDtoHAsync
                   10.00%  46.194ms         1  46.194ms  46.194ms  46.194ms  cuMemHostAlloc
                    7.18%  33.188ms      7200  4.6090us  3.5990us  768.13us  cuLaunchKernel
                    4.91%  22.709ms      3630  6.2550us  2.9330us  777.34us  cuMemcpyHtoDAsync
                    0.45%  2.0931ms      7200     290ns     180ns  10.551us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.27%  1.2312ms         1  1.2312ms  1.2312ms  1.2312ms  cuMemAllocHost
                    0.23%  1.0520ms      7209     145ns     118ns  11.310us  cuDeviceGetAttribute
                    0.14%  632.88us      1217     520ns     379ns  5.6810us  cuPointerGetAttributes
                    0.10%  444.32us         1  444.32us  444.32us  444.32us  cuModuleLoadDataEx
                    0.05%  228.38us        18  12.687us  2.5920us  126.24us  cuMemAlloc
                    0.00%  21.742us         1  21.742us  21.742us  21.742us  cuCtxGetCurrent
                    0.00%  11.367us         1  11.367us  11.367us  11.367us  cuDeviceGetPCIBusId
                    0.00%  2.9900us         3     996ns     207ns  1.8440us  cuCtxSetCurrent
                    0.00%  1.9270us         2     963ns     428ns  1.4990us  cuModuleGetFunction
                    0.00%  1.3220us         3     440ns     171ns     962ns  cuDeviceGetCount
                    0.00%     921ns         3     307ns     140ns     593ns  cuDriverGetVersion
                    0.00%     685ns         2     342ns     135ns     550ns  cuDeviceGet
                    0.00%     390ns         1     390ns     390ns     390ns  cuDeviceComputeCapability
 OpenACC (excl):   27.75%  116.06ms      7200  16.118us  1.6780us  54.986us  acc_wait@layers.c:80
                   15.89%  66.454ms      3600  18.459us  11.864us  98.475us  acc_enqueue_download@layers.c:107 (Y[:l->out_size])
                   11.63%  48.656ms      7200  6.7570us  2.1660us  752.52us  acc_wait@layers.c:61
                   11.18%  46.770ms         9  5.1967ms  12.945us  46.377ms  acc_enter_data@layers.c:42
                    6.10%  25.533ms      3600  7.0920us  4.3420us  778.81us  acc_enqueue_upload@layers.c:61 (X[:in_size])
                    5.51%  23.044ms      3600  6.4010us  4.9000us  769.70us  acc_enqueue_launch@layers.c:61 (_8layers_c_pad_input_61_gpu)
                    4.41%  18.438ms      3600  5.1210us  4.4930us  58.582us  acc_enqueue_launch@layers.c:80 (_8layers_c_conv_forward_80_gpu)
                    3.40%  14.225ms      3600  3.9510us  3.2200us  25.225us  acc_enter_data@layers.c:61
                    2.91%  12.188ms      3600  3.3850us  2.4590us  813.72us  acc_enter_data@layers.c:80
                    2.82%  11.781ms      3600  3.2720us  2.5740us  745.87us  acc_compute_construct@layers.c:61
                    2.63%  10.986ms      3600  3.0510us  2.7270us  19.699us  acc_exit_data@layers.c:80
                    2.25%  9.4243ms      3600  2.6170us  1.9370us  786.94us  acc_exit_data@layers.c:61
                    1.72%  7.1886ms      3600  1.9960us  1.7880us  18.903us  acc_wait@layers.c:107
                    1.57%  6.5557ms      3600  1.8210us  1.6150us  18.218us  acc_compute_construct@layers.c:80
                    0.13%  540.06us         1  540.06us  540.06us  540.06us  acc_device_init@layers.c:42
                    0.02%  87.761us        18  4.8750us     934ns  30.760us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.02%  85.206us         9  9.4670us  5.7360us  24.310us  acc_wait@layers.c:42
                    0.01%  57.758us        18  3.2080us     944ns  14.932us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.01%  56.937us         3  18.979us  4.2190us  48.126us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.01%  43.458us         9  4.8280us  1.6400us  17.738us  acc_exit_data@layers.c:53
                    0.01%  40.701us         3  13.567us  7.2950us  17.400us  acc_enqueue_upload@layers.c:295 (l->weights[:l->weights_size])
                    0.01%  31.901us         3  10.633us  7.4640us  12.316us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.01%  21.184us         3  7.0610us  3.5520us  9.0170us  acc_wait@layers.c:295
                    0.00%  14.280us         3  4.7600us  2.9930us  8.1450us  acc_update@layers.c:295
                    0.00%  12.179us         3  4.0590us  3.7630us  4.3360us  acc_enqueue_upload@layers.c:295 (l->bias[:l->out_depth])
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:80
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:61
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_create@layers.c:80
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_create@layers.c:61
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_delete@layers.c:73
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_delete@layers.c:107
```

#### NV_ACC_TIME

```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.019020 seconds
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Create Network time:0.297665 seconds
Load Network Parameters time:0.008259 seconds
Create Ouputs time:0.000052 seconds

Net Forward total time:0.451383 seconds
    Time for conv1: 0.145363 seconds
    Time for relu1: 0.011051 seconds
    Time for pool1: 0.047586 seconds
    Time for conv2: 0.123166 seconds
    Time for relu2: 0.003544 seconds
    Time for pool2: 0.015242 seconds
    Time for conv3: 0.094788 seconds
    Time for relu3: 0.000975 seconds
    Time for pool3: 0.003907 seconds
    Time for fc: 0.005128 seconds
    Time for softmax: 0.000290 seconds

  Conv: 0.363316 seconds
  ReLU: 0.015570 seconds
  Pool: 0.066734 seconds
  FC:   0.005128 seconds
  Softmax: 0.000290 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000016 seconds
Free memory time:0.001335 seconds
Total time:0.777729 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 302
    42: data region reached 9 times
        42: data copyin transfers: 24
             device time(us): total=302 max=36 min=4 avg=12
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 185
    53: data region reached 9 times
        53: data copyin transfers: 18
             device time(us): total=185 max=36 min=3 avg=10
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  pad_input  NVIDIA  devicenum=0
    time(us): 26,532
    61: compute region reached 3600 times
        61: kernel launched 3600 times
            grid: [960]  block: [128]
            elapsed time(us): total=50,524 max=31 min=12 avg=14
    61: data region reached 7200 times
        61: data copyin transfers: 3600
             device time(us): total=26,532 max=25 min=4 avg=7
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 56,564
    80: compute region reached 3600 times
        80: kernel launched 3600 times
            grid: [160-512]  block: [32x4]
            elapsed time(us): total=131,360 max=66 min=21 avg=36
    80: data region reached 7200 times
        107: data copyout transfers: 3600
             device time(us): total=56,564 max=79 min=9 avg=15
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 55
    295: update directive reached 3 times
        295: data copyin transfers: 6
             device time(us): total=55 max=21 min=3 avg=9
```

### 50k images

```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.731871 seconds
Create Network time:0.192812 seconds
Load Network Parameters time:0.008847 seconds
Create Ouputs time:0.000370 seconds

Net Forward total time:15.143169 seconds
    Time for conv1: 5.022130 seconds
    Time for relu1: 0.452668 seconds
    Time for pool1: 2.004852 seconds
    Time for conv2: 3.831714 seconds
    Time for relu2: 0.144259 seconds
    Time for pool2: 0.642803 seconds
    Time for conv3: 2.601377 seconds
    Time for relu3: 0.038545 seconds
    Time for pool3: 0.162541 seconds
    Time for fc: 0.215087 seconds
    Time for softmax: 0.012213 seconds

  Conv: 11.455220 seconds
  ReLU: 0.635471 seconds
  Pool: 2.810196 seconds
  FC:   0.215087 seconds
  Softmax: 0.012213 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000727 seconds
Free memory time:0.037684 seconds
Total time:16.115482 seconds
END!
```

#### nvprof
```
$ nvprof ./cnn-cifar10-profile 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.683082 seconds
==995807== NVPROF is profiling process 995807, command: ./cnn-cifar10-profile
Create Network time:0.453955 seconds
Load Network Parameters time:0.007857 seconds
Create Ouputs time:0.000334 seconds

Net Forward total time:19.080389 seconds
    Time for conv1: 6.457472 seconds
    Time for relu1: 0.644145 seconds
    Time for pool1: 1.584772 seconds
    Time for conv2: 5.255937 seconds
    Time for relu2: 0.207493 seconds
    Time for pool2: 0.512153 seconds
    Time for conv3: 3.969064 seconds
    Time for relu3: 0.055462 seconds
    Time for pool3: 0.135700 seconds
    Time for fc: 0.219324 seconds
    Time for softmax: 0.014948 seconds

  Conv: 15.682473 seconds
  ReLU: 0.907099 seconds
  Pool: 2.232625 seconds
  FC:   0.219324 seconds
  Softmax: 0.014948 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000749 seconds
Free memory time:0.039546 seconds
Total time:20.265911 seconds
END!
==995807== Profiling application: ./cnn-cifar10-profile
==995807== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   75.53%  3.99611s    150000  26.640us  12.128us  38.944us  _8layers_c_conv_forward_80_gpu
                    9.77%  516.87ms    150000  3.4450us  3.2310us  13.569us  _8layers_c_pad_input_61_gpu
                    8.87%  469.06ms    150000  3.1270us  1.4390us  18.719us  [CUDA memcpy DtoH]
                    5.83%  308.68ms    150030  2.0570us     735ns  5.7920us  [CUDA memcpy HtoD]
      API calls:   54.75%  6.54619s    750012  8.7280us  1.0530us  1.5429ms  cuStreamSynchronize
                   22.25%  2.66031s    150000  17.735us  10.855us  9.4123ms  cuMemcpyDtoHAsync
                   10.80%  1.29108s    300000  4.3030us  3.4240us  5.6643ms  cuLaunchKernel
                    9.33%  1.11508s    150030  7.4320us  2.5710us  2.1634ms  cuMemcpyHtoDAsync
                    1.14%  136.08ms         1  136.08ms  136.08ms  136.08ms  cuDevicePrimaryCtxRetain
                    0.71%  85.355ms    300000     284ns     177ns  178.95us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.44%  52.318ms    300009     174ns     119ns  928.91us  cuDeviceGetAttribute
                    0.38%  45.016ms         1  45.016ms  45.016ms  45.016ms  cuMemHostAlloc
                    0.20%  23.404ms     50018     467ns     329ns  26.034us  cuPointerGetAttributes
                    0.01%  1.3040ms         1  1.3040ms  1.3040ms  1.3040ms  cuMemAllocHost
                    0.00%  451.10us         1  451.10us  451.10us  451.10us  cuModuleLoadDataEx
                    0.00%  243.51us        18  13.528us  2.3230us  143.63us  cuMemAlloc
                    0.00%  18.165us         1  18.165us  18.165us  18.165us  cuDeviceGetPCIBusId
                    0.00%  10.091us         1  10.091us  10.091us  10.091us  cuCtxGetCurrent
                    0.00%  3.2310us         3  1.0770us     244ns  1.9030us  cuCtxSetCurrent
                    0.00%  2.1700us         2  1.0850us     432ns  1.7380us  cuModuleGetFunction
                    0.00%  2.0850us         3     695ns     165ns  1.6690us  cuDeviceGetCount
                    0.00%  1.0030us         3     334ns     138ns     529ns  cuDriverGetVersion
                    0.00%     647ns         2     323ns     206ns     441ns  cuDeviceGet
                    0.00%     458ns         1     458ns     458ns     458ns  cuDeviceComputeCapability
 OpenACC (excl):   31.30%  4.81178s    300000  16.039us  1.6520us  1.5535ms  acc_wait@layers.c:80
                   18.13%  2.78724s    150000  18.581us  11.588us  9.4153ms  acc_enqueue_download@layers.c:107 (Y[:l->out_size])
                   12.98%  1.99577s    300000  6.6520us  1.9300us  982.06us  acc_wait@layers.c:61
                    8.11%  1.24635s    150000  8.3080us  4.0570us  2.1656ms  acc_enqueue_upload@layers.c:61 (X[:in_size])
                    5.51%  847.63ms    150000  5.6500us  4.8090us  1.0160ms  acc_enqueue_launch@layers.c:61 (_8layers_c_pad_input_61_gpu)
                    5.18%  795.70ms    150000  5.3040us  4.4030us  5.6674ms  acc_enqueue_launch@layers.c:80 (_8layers_c_conv_forward_80_gpu)
                    3.86%  593.40ms    150000  3.9560us  3.0840us  1.0824ms  acc_enter_data@layers.c:61
                    2.98%  457.64ms    150000  3.0500us  2.6080us  1.6357ms  acc_exit_data@layers.c:80
                    2.83%  435.69ms    150000  2.9040us  2.5000us  954.55us  acc_compute_construct@layers.c:61
                    2.78%  427.14ms    150000  2.8470us  2.3410us  1.7148ms  acc_enter_data@layers.c:80
                    2.23%  343.42ms    150000  2.2890us  1.8710us  1.3343ms  acc_exit_data@layers.c:61
                    1.98%  304.05ms    150000  2.0260us  1.7110us  992.27us  acc_wait@layers.c:107
                    1.84%  282.40ms    150000  1.8820us  1.5880us  951.69us  acc_compute_construct@layers.c:80
                    0.30%  45.587ms         9  5.0652ms  9.6750us  45.202ms  acc_enter_data@layers.c:42
                    0.00%  545.61us         1  545.61us  545.61us  545.61us  acc_device_init@layers.c:42
                    0.00%  91.263us         9  10.140us  5.2170us  37.692us  acc_wait@layers.c:42
                    0.00%  87.724us        18  4.8730us     868ns  43.557us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.00%  82.278us        18  4.5710us     832ns  27.167us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.00%  60.375us         9  6.7080us  1.6410us  34.679us  acc_exit_data@layers.c:53
                    0.00%  43.459us         3  14.486us  3.9170us  35.339us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.00%  39.534us         3  13.178us  7.9570us  17.082us  acc_enqueue_upload@layers.c:295 (l->weights[:l->weights_size])
                    0.00%  31.866us         3  10.622us  7.3090us  13.002us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.00%  23.868us         3  7.9560us  4.0460us  10.910us  acc_wait@layers.c:295
                    0.00%  13.919us         3  4.6390us  2.6710us  8.4210us  acc_update@layers.c:295
                    0.00%  10.977us         3  3.6590us  3.2880us  4.0030us  acc_enqueue_upload@layers.c:295 (l->bias[:l->out_depth])
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:80
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:61
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_create@layers.c:80
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_create@layers.c:61
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_delete@layers.c:73
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_delete@layers.c:107
```

#### NV_ACC_TIME
```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.741316 seconds
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Create Network time:0.309044 seconds
Load Network Parameters time:0.008486 seconds
Create Ouputs time:0.000354 seconds

Net Forward total time:19.056329 seconds
    Time for conv1: 6.275087 seconds
    Time for relu1: 0.449012 seconds
    Time for pool1: 1.952749 seconds
    Time for conv2: 5.143734 seconds
    Time for relu2: 0.152422 seconds
    Time for pool2: 0.624123 seconds
    Time for conv3: 4.022744 seconds
    Time for relu3: 0.039656 seconds
    Time for pool3: 0.158698 seconds
    Time for fc: 0.210925 seconds
    Time for softmax: 0.012408 seconds

  Conv: 15.441566 seconds
  ReLU: 0.641090 seconds
  Pool: 2.735570 seconds
  FC:   0.210925 seconds
  Softmax: 0.012408 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000711 seconds
Free memory time:0.037389 seconds
Total time:20.153630 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 292
    42: data region reached 9 times
        42: data copyin transfers: 24
             device time(us): total=292 max=38 min=3 avg=12
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 193
    53: data region reached 9 times
        53: data copyin transfers: 18
             device time(us): total=193 max=29 min=3 avg=10
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  pad_input  NVIDIA  devicenum=0
    time(us): 1,348,934
    61: compute region reached 150000 times
        61: kernel launched 150000 times
            grid: [960]  block: [128]
            elapsed time(us): total=2,147,723 max=820 min=13 avg=14
    61: data region reached 300000 times
        61: data copyin transfers: 150000
             device time(us): total=1,348,934 max=65 min=3 avg=8
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 2,397,935
    80: compute region reached 150000 times
        80: kernel launched 150000 times
            grid: [160-512]  block: [32x4]
            elapsed time(us): total=5,268,666 max=2,545 min=21 avg=35
    80: data region reached 300000 times
        107: data copyout transfers: 150000
             device time(us): total=2,397,935 max=349 min=8 avg=15
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 58
    295: update directive reached 3 times
        295: data copyin transfers: 6
             device time(us): total=58 max=23 min=3 avg=9
```

### firstprivate

```c
File: layers.c
060: void pad_input(float* restrict X, Conv_Layer* l) {
061:   int c;
062:   int in_size = l->in_width * l->in_height * l->in_depth;
063: #pragma acc parallel loop present(l) copyin(X[0:in_size]) private(c) vector_length(128)
064:   for (c = 0; c < l->in_depth; c++) {
065:   #pragma acc loop firstprivate(c)
066:     for (int j = 0; j < l->in_height; j++) {
067:     #pragma acc loop vector
068:       for (int i = 0; i < l->in_width; i++) {
069:         int padded_idx = (j + l->padding) * l->padded_width + (i + l->padding) + c * l->padded_height * l->padded_width;
070:         int in_idx = j * l->in_width + i + c * l->in_height * l->in_width;
071:         l->in_padded[padded_idx] = X[in_idx];
072:       }
073:     }
074:   }
075: }
076: 
077: 
078: // Performs the forward pass for a convolutional layer.
079: // X: Input data, l: Convolutional layer, Y: Output data
080: void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
081:   pad_input(X, l); //Create input with zero-padding
082:   int m;
083:   // For each output feature map
084: #pragma acc parallel loop present(l) copyout(Y[0:l->out_size]) gang collapse(2) vector_length(32) //private(m)
085:   for (m = 0; m < l->out_depth; m++) {
086:     for (int j = 0; j < l->out_height; j++) {
087:     #pragma acc loop worker firstprivate(m)
088:       for (int i = 0; i < l->out_width; i++) {
089:         int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
090:         // Calculate dot product of Weights*Input
091:         float sum = 0.0f;
092:       #pragma acc loop reduction(+:sum) vector //cache(l->weights[(m * l->in_depth * l->filter_width * l->filter_width):(l->in_depth * l->filter_width * l->filter_width)])
093:         for (int c = 0; c < l->in_depth; c++) {
094:           for (int f_j = 0; f_j < l->filter_width; f_j++) {
095:             for (int f_i = 0; f_i < l->filter_width; f_i++) {
096:               int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
097:               int x_j = j * l->stride + f_j; // Input height index, increased by stride
098:               int x_i = i * l->stride + f_i; // Input width index, increased by stride
099:               int x_idx = c * l->padded_height * l->padded_width + x_j * l->padded_width + x_i; // Input index
100:               sum += l->weights[f_idx] * l->in_padded[x_idx];
101:             } // for f_i
102:           } // for f_j
103:         } // for c
104:         sum += l->bias[m]; // Add bias
105:         Y[y_idx] = sum; // Save output result
106:       } // for i
107:     } // for j
108:   } // for m
109: }

```

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c main.c -o main.o
arr2txt:
    332, Zero trip check eliminated
arr2txt_2:
    354, Zero trip check eliminated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     64, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating NVIDIA GPU code
         64, #pragma acc loop gang /* blockIdx.x */
         66, #pragma acc loop seq
         68, #pragma acc loop vector(128) /* threadIdx.x */
     66, Loop is parallelizable
     68, Loop is parallelizable
conv_forward:
     85, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating NVIDIA GPU code
         85, #pragma acc loop gang collapse(2) /* blockIdx.x */
         86,   /* blockIdx.x collapsed */
         88, #pragma acc loop worker(4) /* threadIdx.y */
         93, #pragma acc loop vector(32) /* threadIdx.x */
             Generating reduction(+:sum)
         94, #pragma acc loop seq
         95, #pragma acc loop seq
        102, Vector barrier inserted for vector loop reduction
     88, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     95, Loop is parallelizable
    100, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    183, Zero trip check eliminated
fc_forward:
    238, FMA (fused multiply-add) instruction(s) generated
load_conv:
    296, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-pad$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.687760 seconds
Create Network time:0.222531 seconds
Load Network Parameters time:0.007984 seconds
Create Ouputs time:0.000323 seconds

Net Forward total time:14.002999 seconds
    Time for conv1: 4.581862 seconds
    Time for relu1: 0.445672 seconds
    Time for pool1: 1.952279 seconds
    Time for conv2: 3.507109 seconds
    Time for relu2: 0.147387 seconds
    Time for pool2: 0.624058 seconds
    Time for conv3: 2.310334 seconds
    Time for relu3: 0.040385 seconds
    Time for pool3: 0.157810 seconds
    Time for fc: 0.210419 seconds
    Time for softmax: 0.011605 seconds

  Conv: 10.399305 seconds
  ReLU: 0.633444 seconds
  Pool: 2.734147 seconds
  FC:   0.210419 seconds
  Softmax: 0.011605 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000680 seconds
Free memory time:0.044189 seconds
Total time:14.966467 seconds
END!
```

#### NV_ACC_TIME=1
```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.704063 seconds
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Create Network time:0.344473 seconds
Load Network Parameters time:0.009132 seconds
Create Ouputs time:0.000372 seconds

Net Forward total time:17.978204 seconds
    Time for conv1: 5.881185 seconds
    Time for relu1: 0.462911 seconds
    Time for pool1: 1.944840 seconds
    Time for conv2: 4.792425 seconds
    Time for relu2: 0.145730 seconds
    Time for pool2: 0.622695 seconds
    Time for conv3: 3.691439 seconds
    Time for relu3: 0.043448 seconds
    Time for pool3: 0.156832 seconds
    Time for fc: 0.209997 seconds
    Time for softmax: 0.012151 seconds

  Conv: 14.365049 seconds
  ReLU: 0.652089 seconds
  Pool: 2.724367 seconds
  FC:   0.209997 seconds
  Softmax: 0.012151 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000744 seconds
Free memory time:0.045257 seconds
Total time:19.082244 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 306
    42: data region reached 9 times
        42: data copyin transfers: 24
             device time(us): total=306 max=40 min=4 avg=12
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 209
    53: data region reached 9 times
        53: data copyin transfers: 18
             device time(us): total=209 max=38 min=3 avg=11
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  pad_input  NVIDIA  devicenum=0
    time(us): 1,303,725
    64: compute region reached 150000 times
        64: kernel launched 150000 times
            grid: [960]  block: [128]
            elapsed time(us): total=1,951,756 max=1,712 min=12 avg=13
    64: data region reached 300000 times
        64: data copyin transfers: 150000
             device time(us): total=1,303,725 max=3,603 min=3 avg=8
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 2,306,693
    85: compute region reached 150000 times
        85: kernel launched 150000 times
            grid: [160-512]  block: [32x4]
            elapsed time(us): total=4,940,393 max=3,607 min=19 avg=32
    85: data region reached 300000 times
        108: data copyout transfers: 150000
             device time(us): total=2,306,693 max=1,069 min=8 avg=15
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-pad/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 63
    296: update directive reached 3 times
        296: data copyin transfers: 6
             device time(us): total=63 max=24 min=3 avg=10
```

#### nvprof

```
$ nvprof ./cnn-cifar10-profile 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.688848 seconds
==2663084== NVPROF is profiling process 2663084, command: ./cnn-cifar10-profile
Create Network time:0.565915 seconds
Load Network Parameters time:0.008129 seconds
Create Ouputs time:0.000330 seconds

Net Forward total time:19.279343 seconds
    Time for conv1: 6.917129 seconds
    Time for relu1: 0.697517 seconds
    Time for pool1: 1.559051 seconds
    Time for conv2: 5.120366 seconds
    Time for relu2: 0.204065 seconds
    Time for pool2: 0.505995 seconds
    Time for conv3: 3.827665 seconds
    Time for relu3: 0.064111 seconds
    Time for pool3: 0.129804 seconds
    Time for fc: 0.215548 seconds
    Time for softmax: 0.014447 seconds

  Conv: 15.865161 seconds
  ReLU: 0.965693 seconds
  Pool: 2.194850 seconds
  FC:   0.215548 seconds
  Softmax: 0.014447 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000916 seconds
Free memory time:0.047408 seconds
Total time:20.590889 seconds
END!
==2663084== Profiling application: ./cnn-cifar10-profile
==2663084== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   74.99%  3.87374s    150000  25.824us  11.679us  37.312us  _8layers_c_conv_forward_85_gpu
                   10.16%  524.73ms    150000  3.4980us  3.2950us  13.504us  _8layers_c_pad_input_64_gpu
                    8.89%  459.01ms    150000  3.0600us  1.4390us  18.464us  [CUDA memcpy DtoH]
                    5.97%  308.38ms    150030  2.0550us     735ns  5.7600us  [CUDA memcpy HtoD]
      API calls:   50.84%  6.21598s    750012  8.2870us  1.0560us  1.6144ms  cuStreamSynchronize
                   21.85%  2.67101s    150000  17.806us  10.554us  7.6772ms  cuMemcpyDtoHAsync
                   13.48%  1.64754s    150030  10.981us  2.6360us  2.4289ms  cuMemcpyHtoDAsync
                   10.84%  1.32553s    300000  4.4180us  3.5320us  6.2373ms  cuLaunchKernel
                    1.26%  154.25ms         1  154.25ms  154.25ms  154.25ms  cuDevicePrimaryCtxRetain
                    0.68%  83.021ms    300000     276ns     179ns  16.911us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.42%  51.736ms    300009     172ns     120ns  794.23us  cuDeviceGetAttribute
                    0.37%  45.548ms         1  45.548ms  45.548ms  45.548ms  cuMemHostAlloc
                    0.23%  27.538ms     50023     550ns     346ns  3.3734ms  cuPointerGetAttributes
                    0.02%  2.1042ms        18  116.90us  2.4690us  2.0042ms  cuMemAlloc
                    0.01%  1.2628ms         1  1.2628ms  1.2628ms  1.2628ms  cuMemAllocHost
                    0.00%  479.29us         1  479.29us  479.29us  479.29us  cuModuleLoadDataEx
                    0.00%  14.027us         2  7.0130us     460ns  13.567us  cuModuleGetFunction
                    0.00%  12.423us         1  12.423us  12.423us  12.423us  cuDeviceGetPCIBusId
                    0.00%  3.0200us         3  1.0060us     210ns  1.9040us  cuCtxSetCurrent
                    0.00%  2.4820us         3     827ns     194ns  2.0200us  cuDeviceGetCount
                    0.00%  1.4140us         2     707ns     191ns  1.2230us  cuDeviceGet
                    0.00%  1.1140us         3     371ns     164ns     501ns  cuDriverGetVersion
                    0.00%     714ns         1     714ns     714ns     714ns  cuCtxGetCurrent
                    0.00%     674ns         1     674ns     674ns     674ns  cuDeviceComputeCapability
 OpenACC (excl):   29.63%  4.61105s    300000  15.370us  1.6490us  1.6253ms  acc_wait@layers.c:85
                   18.00%  2.80076s    150000  18.671us  11.307us  7.6796ms  acc_enqueue_download@layers.c:108 (Y[:l->out_size])
                   11.90%  1.85271s    300000  6.1750us  1.9730us  848.91us  acc_wait@layers.c:64
                   11.40%  1.77466s    150000  11.831us  3.9830us  2.4312ms  acc_enqueue_upload@layers.c:64 (X[:in_size])
                    5.61%  873.50ms    150000  5.8230us  4.9930us  839.82us  acc_enqueue_launch@layers.c:64 (_8layers_c_pad_input_64_gpu)
                    5.08%  791.25ms    150000  5.2750us  4.4910us  6.2409ms  acc_enqueue_launch@layers.c:85 (_8layers_c_conv_forward_85_gpu)
                    3.85%  598.85ms    150000  3.9920us  3.1430us  3.4214ms  acc_enter_data@layers.c:64
                    2.95%  459.35ms    150000  3.0620us  2.6280us  806.00us  acc_exit_data@layers.c:85
                    2.75%  427.42ms    150000  2.8490us  2.4630us  1.0149ms  acc_compute_construct@layers.c:64
                    2.70%  420.31ms    150000  2.8020us  2.3880us  845.00us  acc_enter_data@layers.c:85
                    2.16%  336.53ms    150000  2.2430us  1.8750us  2.7701ms  acc_exit_data@layers.c:64
                    1.89%  294.91ms    150000  1.9660us  1.6710us  860.92us  acc_wait@layers.c:108
                    1.76%  274.59ms    150000  1.8300us  1.6000us  787.55us  acc_compute_construct@layers.c:85
                    0.30%  46.162ms         9  5.1291ms  12.896us  45.738ms  acc_enter_data@layers.c:42
                    0.00%  570.93us         1  570.93us  570.93us  570.93us  acc_device_init@layers.c:42
                    0.00%  97.775us         9  10.863us  4.7330us  40.738us  acc_wait@layers.c:42
                    0.00%  88.950us        18  4.9410us     878ns  30.244us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.00%  67.750us        18  3.7630us     889ns  24.027us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.00%  58.065us         3  19.355us  4.2580us  49.052us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.00%  50.867us         9  5.6510us  1.7160us  24.425us  acc_exit_data@layers.c:53
                    0.00%  40.507us         3  13.502us  7.3520us  18.830us  acc_enqueue_upload@layers.c:296 (l->weights[:l->weights_size])
                    0.00%  32.623us         3  10.874us  7.7820us  12.535us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.00%  21.268us         3  7.0890us  3.4870us  9.0630us  acc_wait@layers.c:296
                    0.00%  13.891us         3  4.6300us  2.8000us  7.9020us  acc_update@layers.c:296
                    0.00%  10.844us         3  3.6140us  3.3430us  3.8470us  acc_enqueue_upload@layers.c:296 (l->bias[:l->out_depth])
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:85
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:64
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_create@layers.c:85
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_create@layers.c:64
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_delete@layers.c:74
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
                    0.00%       0ns    150000       0ns       0ns       0ns  acc_delete@layers.c:108
```
