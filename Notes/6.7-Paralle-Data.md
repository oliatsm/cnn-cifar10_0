# Data Transfers

## if
### Without Reduction

```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) copyout(Y[0:l->out_size]) present(l)
  {
    // For each output feature map
  #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
    #pragma acc loop independent
      for (int j = 0; j < l->out_height; j++) {
      #pragma acc loop independent
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
                int x_j = -l->padding + j * l->stride + f_j; // Input height index, increased by stride
                int x_i = -l->padding + i * l->stride + f_i; // Input width index, increased by stride
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
                ...
}

```

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     35, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size],layer->bias[:M])
free_conv:
     43, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->weights_size])
conv_forward:
     53, Generating copyin(X[:in_size]) [if not already present]
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating present(l[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         56, #pragma acc loop gang /* blockIdx.x */
         58, #pragma acc loop seq
         60, #pragma acc loop seq
         65, #pragma acc loop seq
         66, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
             Generating implicit reduction(+:sum)
     58, Loop is parallelizable
     60, Loop is parallelizable
     65, Loop is parallelizable
     66, Loop is parallelizable
     67, Loop is parallelizable
     74, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    159, Zero trip check eliminated
fc_forward:
    214, FMA (fused multiply-add) instruction(s) generated
load_conv:
    272, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-if$ ./cnn-cifar10 
Paralle (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.020790 seconds
Create Network time:0.224698 seconds
Load Network Parameters time:0.008401 seconds
Create Ouputs time:0.000032 seconds

Net Forward total time:13.344381 seconds
    Time for conv1: 4.942289 seconds
    Time for relu1: 0.013209 seconds
    Time for pool1: 0.052103 seconds
    Time for conv2: 6.310724 seconds
    Time for relu2: 0.004905 seconds
    Time for pool2: 0.017289 seconds
    Time for conv3: 1.992456 seconds
    Time for relu3: 0.001111 seconds
    Time for pool3: 0.004111 seconds
    Time for fc: 0.005433 seconds
    Time for softmax: 0.000362 seconds

  Conv: 13.245470 seconds
  ReLU: 0.019225 seconds
  Pool: 0.073503 seconds
  FC:   0.005433 seconds
  Softmax: 0.000362 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000022 seconds
Free memory time:0.001397 seconds
Total time:13.599721 seconds
END!
```
---
### With Reduction
```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) copyout(Y[0:l->out_size]) present(l)
  {
    // For each output feature map
  #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
    #pragma acc loop independent
      for (int j = 0; j < l->out_height; j++) {
      #pragma acc loop independent
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum)
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
                int x_j = -l->padding + j * l->stride + f_j; // Input height index, increased by stride
                int x_i = -l->padding + i * l->stride + f_i; // Input width index, increased by stride
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
                ...
}

```

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     35, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size],layer->bias[:M])
free_conv:
     43, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->weights_size])
conv_forward:
     53, Generating copyin(X[:in_size]) [if not already present]
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating present(l[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         56, #pragma acc loop gang /* blockIdx.x */
         58, #pragma acc loop seq
         60, #pragma acc loop seq
         65, #pragma acc loop seq
         66, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     58, Loop is parallelizable
     60, Loop is parallelizable
     65, Loop is parallelizable
     66, Loop is parallelizable
     67, Loop is parallelizable
     74, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    159, Zero trip check eliminated
fc_forward:
    214, FMA (fused multiply-add) instruction(s) generated
load_conv:
    272, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o

olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-if$ ./cnn-cifar10 
Parallel (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022330 seconds
Create Network time:0.194666 seconds
Load Network Parameters time:0.008219 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:5.674153 seconds
    Time for conv1: 2.731620 seconds
    Time for relu1: 0.015364 seconds
    Time for pool1: 0.049917 seconds
    Time for conv2: 2.168491 seconds
    Time for relu2: 0.004067 seconds
    Time for pool2: 0.015903 seconds
    Time for conv3: 0.677569 seconds
    Time for relu3: 0.001060 seconds
    Time for pool3: 0.004021 seconds
    Time for fc: 0.005361 seconds
    Time for softmax: 0.000372 seconds

  Conv: 5.577681 seconds
  ReLU: 0.020491 seconds
  Pool: 0.069842 seconds
  FC:   0.005361 seconds
  Softmax: 0.000372 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000023 seconds
Free memory time:0.001369 seconds
Total time:5.900793 seconds
END!
```
### 50k images

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.745508 seconds
Create Network time:0.220606 seconds
Load Network Parameters time:0.008402 seconds
Create Ouputs time:0.000339 seconds

Net Forward total time:236.735320 seconds
    Time for conv1: 113.976139 seconds
    Time for relu1: 0.572837 seconds
    Time for pool1: 2.169167 seconds
    Time for conv2: 90.407303 seconds
    Time for relu2: 0.183733 seconds
    Time for pool2: 0.692584 seconds
    Time for conv3: 28.242542 seconds
    Time for relu3: 0.046555 seconds
    Time for pool3: 0.176510 seconds
    Time for fc: 0.232567 seconds
    Time for softmax: 0.017279 seconds

  Conv: 232.625984 seconds
  ReLU: 0.803125 seconds
  Pool: 3.038261 seconds
  FC:   0.232567 seconds
  Softmax: 0.017279 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000748 seconds
Free memory time:0.053699 seconds
Total time:237.764622 seconds
END!
```
---

## Pad
### with Reduction

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang /* blockIdx.x */
         86, #pragma acc loop seq
         88, #pragma acc loop seq
         92, #pragma acc loop seq
         93, #pragma acc loop seq
         94, #pragma acc loop vector(128) /* threadIdx.x */
             Generating implicit reduction(+:sum)
     86, Loop is parallelizable
     88, Loop is parallelizable
     92, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     99, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    182, Zero trip check eliminated
fc_forward:
    237, FMA (fused multiply-add) instruction(s) generated
load_conv:
    295, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-pad$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022192 seconds
Create Network time:0.227637 seconds
Load Network Parameters time:0.009352 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:11.421135 seconds
    Time for conv1: 4.228448 seconds
    Time for relu1: 0.014668 seconds
    Time for pool1: 0.052956 seconds
    Time for conv2: 5.375016 seconds
    Time for relu2: 0.004450 seconds
    Time for pool2: 0.017326 seconds
    Time for conv3: 1.716275 seconds
    Time for relu3: 0.001211 seconds
    Time for pool3: 0.004333 seconds
    Time for fc: 0.005578 seconds
    Time for softmax: 0.000417 seconds

  Conv: 11.319739 seconds
  ReLU: 0.020329 seconds
  Pool: 0.074615 seconds
  FC:   0.005578 seconds
  Softmax: 0.000417 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000022 seconds
Free memory time:0.001491 seconds
Total time:11.681861 seconds
END!
```

### with Reduction
```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang /* blockIdx.x */
         86, #pragma acc loop seq
         88, #pragma acc loop seq
         93, #pragma acc loop seq
         94, #pragma acc loop seq
         95, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     86, Loop is parallelizable
     88, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     95, Loop is parallelizable
    100, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    183, Zero trip check eliminated
fc_forward:
    238, FMA (fused multiply-add) instruction(s) generated
load_conv:
    296, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o

$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.023128 seconds
Create Network time:0.227325 seconds
Load Network Parameters time:0.008866 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:3.827113 seconds
    Time for conv1: 2.022345 seconds
    Time for relu1: 0.015537 seconds
    Time for pool1: 0.051935 seconds
    Time for conv2: 1.283414 seconds
    Time for relu2: 0.004531 seconds
    Time for pool2: 0.016871 seconds
    Time for conv3: 0.420664 seconds
    Time for relu3: 0.001219 seconds
    Time for pool3: 0.004199 seconds
    Time for fc: 0.005525 seconds
    Time for softmax: 0.000429 seconds

  Conv: 3.726423 seconds
  ReLU: 0.021287 seconds
  Pool: 0.073006 seconds
  FC:   0.005525 seconds
  Softmax: 0.000429 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000041 seconds
Free memory time:0.001771 seconds
Total time:4.088277 seconds
END!
```

