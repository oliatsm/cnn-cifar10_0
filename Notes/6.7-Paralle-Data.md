# Data Transfers

## -gpu=managed
### 1200 images
#### NV_ACC_TIME=1

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 1200 images
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Loading input batch 1...
Load Data time:0.021731 seconds
Create Network time:0.000058 seconds
Load Network Parameters time:0.008021 seconds
Create Ouputs time:0.000049 seconds

Net Forward total time:7.577612 seconds
    Time for conv1: 3.192707 seconds
    Time for relu1: 0.175842 seconds
    Time for pool1: 0.053587 seconds
    Time for conv2: 2.813388 seconds
    Time for relu2: 0.071313 seconds
    Time for pool2: 0.015867 seconds
    Time for conv3: 1.088609 seconds
    Time for relu3: 0.066288 seconds
    Time for pool3: 0.025056 seconds
    Time for fc: 0.073996 seconds
    Time for softmax: 0.000581 seconds

  Conv: 7.094704 seconds
  ReLU: 0.313443 seconds
  Pool: 0.094510 seconds
  FC:   0.073996 seconds
  Softmax: 0.000581 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000021 seconds
Free memory time:0.000071 seconds
Total time:7.607563 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-if/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 0
    50: compute region reached 3600 times
        50: kernel launched 3600 times
            grid: [560]  block: [128]
            elapsed time(us): total=7,078,597 max=3,441 min=685 avg=1,966
    50: data region reached 7200 times
```

#### nvprof

```
$ nvprof ./cnn-cifar10-profile 
Parallel (if) Code
CNN for 1200 images
==3172958== NVPROF is profiling process 3172958, command: ./cnn-cifar10-profile
Loading input batch 1...
Load Data time:0.024031 seconds
Create Network time:0.000089 seconds
Load Network Parameters time:0.008009 seconds
Create Ouputs time:0.000092 seconds

Net Forward total time:8.129776 seconds
    Time for conv1: 3.155518 seconds
    Time for relu1: 0.372521 seconds
    Time for pool1: 0.051608 seconds
    Time for conv2: 2.892638 seconds
    Time for relu2: 0.150814 seconds
    Time for pool2: 0.013042 seconds
    Time for conv3: 1.136566 seconds
    Time for relu3: 0.136822 seconds
    Time for pool3: 0.053488 seconds
    Time for fc: 0.165381 seconds
    Time for softmax: 0.000715 seconds

  Conv: 7.184722 seconds
  ReLU: 0.660157 seconds
  Pool: 0.118138 seconds
  FC:   0.165381 seconds
  Softmax: 0.000715 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000035 seconds
Free memory time:0.000075 seconds
Total time:8.162108 seconds
END!
==3172958== Profiling application: ./cnn-cifar10-profile
==3172958== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:  100.00%  7.10026s      3600  1.9723ms  764.57us  3.4771ms  _8layers_c_conv_forward_50_gpu
      API calls:   96.94%  7.11527s      7200  988.23us  1.3730us  3.4762ms  cuStreamSynchronize
                    2.38%  174.45ms         1  174.45ms  174.45ms  174.45ms  cuDevicePrimaryCtxRetain
                    0.30%  22.304ms      3600  6.1950us  4.7550us  815.00us  cuLaunchKernel
                    0.28%  20.694ms         1  20.694ms  20.694ms  20.694ms  cuMemAllocManaged
                    0.03%  2.4605ms      7200     341ns     186ns  75.124us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.02%  1.7417ms         1  1.7417ms  1.7417ms  1.7417ms  cuMemAllocHost
                    0.02%  1.5382ms      3609     426ns     140ns  778.22us  cuDeviceGetAttribute
                    0.01%  851.50us      1208     704ns     241ns  23.099us  cuPointerGetAttributes
                    0.00%  310.13us         1  310.13us  310.13us  310.13us  cuModuleLoadDataEx
                    0.00%  174.42us         1  174.42us  174.42us  174.42us  cuMemAlloc
                    0.00%  9.5660us         1  9.5660us  9.5660us  9.5660us  cuDeviceGetPCIBusId
                    0.00%  6.8080us         1  6.8080us  6.8080us  6.8080us  cuModuleGetFunction
                    0.00%  3.7060us         3  1.2350us     357ns  1.8120us  cuCtxSetCurrent
                    0.00%  1.7550us         2     877ns     468ns  1.2870us  cuDeviceTotalMem
                    0.00%  1.4900us         3     496ns     133ns  1.1240us  cuDeviceGetCount
                    0.00%     824ns         3     274ns     117ns     488ns  cuDriverGetVersion
                    0.00%     651ns         2     325ns     140ns     511ns  cuDeviceGet
                    0.00%     638ns         1     638ns     638ns     638ns  cuDeviceComputeCapability
                    0.00%     482ns         1     482ns     482ns     482ns  cuCtxGetCurrent
 OpenACC (excl):   99.21%  7.12198s      7200  989.16us  2.0470us  3.4776ms  acc_wait@layers.c:50
                    0.38%  27.165ms      3600  7.5450us  5.9060us  816.80us  acc_enqueue_launch@layers.c:50 (_8layers_c_conv_forward_50_gpu)
                    0.18%  13.034ms      3600  3.6200us  2.6800us  782.63us  acc_compute_construct@layers.c:50
                    0.14%  9.8901ms      3600  2.7470us  1.8690us  126.13us  acc_enter_data@layers.c:50
                    0.08%  6.0874ms      3600  1.6900us  1.2150us  760.11us  acc_exit_data@layers.c:50
                    0.01%  397.57us         1  397.57us  397.57us  397.57us  acc_device_init

==3172958== Unified Memory profiling result:
Device "Tesla V100-PCIE-32GB (0)"
   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name
   19939  13.748KB  4.0000KB  0.9961MB  267.7031MB  66.84819ms  Host To Device
   27896  9.3057KB  4.0000KB  448.00KB  253.5234MB  48.68387ms  Device To Host
    9509         -         -         -           -   1.661236s  Gpu page fault groups
    7645  4.0000KB  4.0000KB  4.0000KB  29.86328MB           -  Memory thrashes
Total CPU Page faults: 18339
Total CPU thrashes: 7645
```


## if
### Without Reduction

```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) copyout(Y[0:l->out_size]) present(l)
  {
    // For each output feature map
  #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
    #pragma acc loop independent
      for (int j = 0; j < l->out_height; j++) {
      #pragma acc loop independent
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
                int x_j = -l->padding + j * l->stride + f_j; // Input height index, increased by stride
                int x_i = -l->padding + i * l->stride + f_i; // Input width index, increased by stride
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
                ...
}

```

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     35, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size],layer->bias[:M])
free_conv:
     43, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->weights_size])
conv_forward:
     53, Generating copyin(X[:in_size]) [if not already present]
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating present(l[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         56, #pragma acc loop gang /* blockIdx.x */
         58, #pragma acc loop seq
         60, #pragma acc loop seq
         65, #pragma acc loop seq
         66, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
             Generating implicit reduction(+:sum)
     58, Loop is parallelizable
     60, Loop is parallelizable
     65, Loop is parallelizable
     66, Loop is parallelizable
     67, Loop is parallelizable
     74, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    159, Zero trip check eliminated
fc_forward:
    214, FMA (fused multiply-add) instruction(s) generated
load_conv:
    272, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-if$ ./cnn-cifar10 
Paralle (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.020790 seconds
Create Network time:0.224698 seconds
Load Network Parameters time:0.008401 seconds
Create Ouputs time:0.000032 seconds

Net Forward total time:13.344381 seconds
    Time for conv1: 4.942289 seconds
    Time for relu1: 0.013209 seconds
    Time for pool1: 0.052103 seconds
    Time for conv2: 6.310724 seconds
    Time for relu2: 0.004905 seconds
    Time for pool2: 0.017289 seconds
    Time for conv3: 1.992456 seconds
    Time for relu3: 0.001111 seconds
    Time for pool3: 0.004111 seconds
    Time for fc: 0.005433 seconds
    Time for softmax: 0.000362 seconds

  Conv: 13.245470 seconds
  ReLU: 0.019225 seconds
  Pool: 0.073503 seconds
  FC:   0.005433 seconds
  Softmax: 0.000362 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000022 seconds
Free memory time:0.001397 seconds
Total time:13.599721 seconds
END!
```
---
### With Reduction
```c
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) copyout(Y[0:l->out_size]) present(l)
  {
    // For each output feature map
  #pragma acc parallel loop
    for (int m = 0; m < l->out_depth; m++) {
    #pragma acc loop independent
      for (int j = 0; j < l->out_height; j++) {
      #pragma acc loop independent
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum)
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
                int x_j = -l->padding + j * l->stride + f_j; // Input height index, increased by stride
                int x_i = -l->padding + i * l->stride + f_i; // Input width index, increased by stride
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
                ...
}

```

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     35, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size],layer->bias[:M])
free_conv:
     43, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->weights_size])
conv_forward:
     53, Generating copyin(X[:in_size]) [if not already present]
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating present(l[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         56, #pragma acc loop gang /* blockIdx.x */
         58, #pragma acc loop seq
         60, #pragma acc loop seq
         65, #pragma acc loop seq
         66, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     58, Loop is parallelizable
     60, Loop is parallelizable
     65, Loop is parallelizable
     66, Loop is parallelizable
     67, Loop is parallelizable
     74, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    159, Zero trip check eliminated
fc_forward:
    214, FMA (fused multiply-add) instruction(s) generated
load_conv:
    272, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o

olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-if$ ./cnn-cifar10 
Parallel (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022330 seconds
Create Network time:0.194666 seconds
Load Network Parameters time:0.008219 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:5.674153 seconds
    Time for conv1: 2.731620 seconds
    Time for relu1: 0.015364 seconds
    Time for pool1: 0.049917 seconds
    Time for conv2: 2.168491 seconds
    Time for relu2: 0.004067 seconds
    Time for pool2: 0.015903 seconds
    Time for conv3: 0.677569 seconds
    Time for relu3: 0.001060 seconds
    Time for pool3: 0.004021 seconds
    Time for fc: 0.005361 seconds
    Time for softmax: 0.000372 seconds

  Conv: 5.577681 seconds
  ReLU: 0.020491 seconds
  Pool: 0.069842 seconds
  FC:   0.005361 seconds
  Softmax: 0.000372 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000023 seconds
Free memory time:0.001369 seconds
Total time:5.900793 seconds
END!
```
#### Profiling

##### NV_ACCC_TIME=1
```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.020446 seconds
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Create Network time:0.332590 seconds
Load Network Parameters time:0.008112 seconds
Create Ouputs time:0.000042 seconds

Net Forward total time:5.759420 seconds
    Time for conv1: 2.765880 seconds
    Time for relu1: 0.011108 seconds
    Time for pool1: 0.046872 seconds
    Time for conv2: 2.201134 seconds
    Time for relu2: 0.003435 seconds
    Time for pool2: 0.014983 seconds
    Time for conv3: 0.705536 seconds
    Time for relu3: 0.001006 seconds
    Time for pool3: 0.003777 seconds
    Time for fc: 0.005054 seconds
    Time for softmax: 0.000287 seconds

  Conv: 5.672550 seconds
  ReLU: 0.015550 seconds
  Pool: 0.065632 seconds
  FC:   0.005054 seconds
  Softmax: 0.000287 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000035 seconds
Free memory time:0.001512 seconds
Total time:6.122157 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-if/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 195
    35: data region reached 6 times
        35: data copyin transfers: 15
             device time(us): total=195 max=34 min=4 avg=13
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-if/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 139
    43: data region reached 6 times
        43: data copyin transfers: 12
             device time(us): total=139 max=25 min=3 avg=11
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-if/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 86,933
    51: compute region reached 3600 times
        51: kernel launched 3600 times
            grid: [560]  block: [128]
            elapsed time(us): total=5,500,239 max=2,528 min=546 avg=1,527
    51: data region reached 7200 times
        51: data copyin transfers: 3600
             device time(us): total=31,908 max=33 min=4 avg=8
        82: data copyout transfers: 3600
             device time(us): total=55,025 max=82 min=8 avg=15
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-if/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 59
    270: update directive reached 3 times
        270: data copyin transfers: 6
             device time(us): total=59 max=24 min=3 avg=9
```

##### nvprof
```
$ nvprof ./cnn-cifar10-profile 
Parallel (if) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.020891 seconds
==3136051== NVPROF is profiling process 3136051, command: ./cnn-cifar10-profile
Create Network time:0.444831 seconds
Load Network Parameters time:0.008428 seconds
Create Ouputs time:0.000052 seconds

Net Forward total time:5.749685 seconds
    Time for conv1: 2.768874 seconds
    Time for relu1: 0.017919 seconds
    Time for pool1: 0.039199 seconds
    Time for conv2: 2.195292 seconds
    Time for relu2: 0.004901 seconds
    Time for pool2: 0.013241 seconds
    Time for conv3: 0.699602 seconds
    Time for relu3: 0.001367 seconds
    Time for pool3: 0.003120 seconds
    Time for fc: 0.005196 seconds
    Time for softmax: 0.000390 seconds

  Conv: 5.663768 seconds
  ReLU: 0.024187 seconds
  Pool: 0.055560 seconds
  FC:   0.005196 seconds
  Softmax: 0.000390 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000032 seconds
Free memory time:0.001336 seconds
Total time:6.225254 seconds
END!
==3136051== Profiling application: ./cnn-cifar10-profile
==3136051== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   99.68%  5.45148s      3600  1.5143ms  535.58us  2.4907ms  _8layers_c_conv_forward_51_gpu
                    0.20%  10.850ms      3600  3.0130us  1.3750us  17.824us  [CUDA memcpy DtoH]
                    0.12%  6.6799ms      3621  1.8440us     672ns  5.7590us  [CUDA memcpy HtoD]
      API calls:   94.89%  5.47680s     10809  506.69us  1.0980us  2.6201ms  cuStreamSynchronize
                    2.39%  138.23ms         1  138.23ms  138.23ms  138.23ms  cuDevicePrimaryCtxRetain
                    1.09%  63.059ms      3600  17.516us  10.665us  643.64us  cuMemcpyDtoHAsync
                    0.73%  41.917ms         1  41.917ms  41.917ms  41.917ms  cuMemHostAlloc
                    0.47%  26.850ms      3621  7.4150us  2.7770us  50.515us  cuMemcpyHtoDAsync
                    0.32%  18.284ms      3600  5.0780us  4.0120us  1.1053ms  cuLaunchKernel
                    0.05%  2.8176ms      7200     391ns     186ns  793.83us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.03%  1.4629ms      3609     405ns     142ns  785.52us  cuDeviceGetAttribute
                    0.02%  1.3256ms         1  1.3256ms  1.3256ms  1.3256ms  cuMemAllocHost
                    0.01%  712.66us      1214     587ns     376ns  24.253us  cuPointerGetAttributes
                    0.00%  210.69us        16  13.168us  2.4880us  138.23us  cuMemAlloc
                    0.00%  178.81us         1  178.81us  178.81us  178.81us  cuModuleLoadDataEx
                    0.00%  17.708us         1  17.708us  17.708us  17.708us  cuDeviceGetPCIBusId
                    0.00%  7.3910us         1  7.3910us  7.3910us  7.3910us  cuCtxGetCurrent
                    0.00%  2.3220us         3     774ns     216ns  1.1350us  cuCtxSetCurrent
                    0.00%  1.4380us         1  1.4380us  1.4380us  1.4380us  cuModuleGetFunction
                    0.00%  1.2850us         3     428ns     121ns     989ns  cuDeviceGetCount
                    0.00%     674ns         2     337ns     169ns     505ns  cuDeviceGet
                    0.00%     526ns         3     175ns     119ns     243ns  cuDriverGetVersion
                    0.00%     382ns         1     382ns     382ns     382ns  cuDeviceComputeCapability
 OpenACC (excl):   96.10%  5.47834s      7200  760.88us  2.0720us  2.6225ms  acc_wait@layers.c:51
                    1.16%  66.292ms      3600  18.414us  11.380us  660.44us  acc_enqueue_download@layers.c:82 (Y[:l->out_size])
                    0.74%  42.263ms         6  7.0438ms  14.152us  42.022ms  acc_enter_data@layers.c:35
                    0.52%  29.610ms      3600  8.2240us  4.2680us  53.232us  acc_enqueue_upload@layers.c:51 (X[:in_size])
                    0.50%  28.362ms      3600  7.8780us  5.0260us  1.1073ms  acc_enqueue_launch@layers.c:51 (_8layers_c_conv_forward_51_gpu)
                    0.36%  20.415ms      3600  5.6700us  4.3680us  1.0832ms  acc_enter_data@layers.c:51
                    0.27%  15.649ms      3600  4.3470us  3.6510us  36.250us  acc_exit_data@layers.c:51
                    0.21%  12.080ms      3600  3.3550us  2.5360us  800.43us  acc_compute_construct@layers.c:51
                    0.13%  7.3243ms      3600  2.0340us  1.7610us  118.02us  acc_wait@layers.c:82
                    0.00%  235.56us         1  235.56us  235.56us  235.56us  acc_device_init@layers.c:35
                    0.00%  73.778us        12  6.1480us     875ns  27.643us  acc_enqueue_upload@layers.c:35 (.attach.)
                    0.00%  51.837us        12  4.3190us     831ns  24.500us  acc_enqueue_upload@layers.c:43 (.detach.)
                    0.00%  47.873us         6  7.9780us  4.5210us  20.131us  acc_wait@layers.c:35
                    0.00%  43.040us         3  14.346us  7.9060us  18.459us  acc_enqueue_upload@layers.c:270 (l->weights[:l->weights_size])
                    0.00%  35.558us         6  5.9260us  1.7600us  21.111us  acc_exit_data@layers.c:43
                    0.00%  27.778us         3  9.2590us  4.3570us  17.721us  acc_enqueue_upload@layers.c:35 (layer[:1])
                    0.00%  21.244us         3  7.0810us  3.5260us  9.2320us  acc_wait@layers.c:270
                    0.00%  15.261us         3  5.0870us  3.0500us  9.0840us  acc_update@layers.c:270
                    0.00%  11.919us         3  3.9730us  3.6440us  4.4390us  acc_enqueue_upload@layers.c:270 (l->bias[:l->out_depth])
                    0.00%       0ns      7200       0ns       0ns       0ns  acc_delete@layers.c:82
                    0.00%       0ns         9       0ns       0ns       0ns  acc_delete@layers.c:43
                    0.00%       0ns         6       0ns       0ns       0ns  acc_alloc@layers.c:51
                    0.00%       0ns      7200       0ns       0ns       0ns  acc_create@layers.c:51
                    0.00%       0ns         9       0ns       0ns       0ns  acc_alloc@layers.c:35
                    0.00%       0ns         9       0ns       0ns       0ns  acc_create@layers.c:35
```

### 50k images

```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.745508 seconds
Create Network time:0.220606 seconds
Load Network Parameters time:0.008402 seconds
Create Ouputs time:0.000339 seconds

Net Forward total time:236.735320 seconds
    Time for conv1: 113.976139 seconds
    Time for relu1: 0.572837 seconds
    Time for pool1: 2.169167 seconds
    Time for conv2: 90.407303 seconds
    Time for relu2: 0.183733 seconds
    Time for pool2: 0.692584 seconds
    Time for conv3: 28.242542 seconds
    Time for relu3: 0.046555 seconds
    Time for pool3: 0.176510 seconds
    Time for fc: 0.232567 seconds
    Time for softmax: 0.017279 seconds

  Conv: 232.625984 seconds
  ReLU: 0.803125 seconds
  Pool: 3.038261 seconds
  FC:   0.232567 seconds
  Softmax: 0.017279 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000748 seconds
Free memory time:0.053699 seconds
Total time:237.764622 seconds
END!
```
---

## Pad
### without Reduction

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang /* blockIdx.x */
         86, #pragma acc loop seq
         88, #pragma acc loop seq
         92, #pragma acc loop seq
         93, #pragma acc loop seq
         94, #pragma acc loop vector(128) /* threadIdx.x */
             Generating implicit reduction(+:sum)
     86, Loop is parallelizable
     88, Loop is parallelizable
     92, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     99, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    182, Zero trip check eliminated
fc_forward:
    237, FMA (fused multiply-add) instruction(s) generated
load_conv:
    295, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-pad$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022192 seconds
Create Network time:0.227637 seconds
Load Network Parameters time:0.009352 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:11.421135 seconds
    Time for conv1: 4.228448 seconds
    Time for relu1: 0.014668 seconds
    Time for pool1: 0.052956 seconds
    Time for conv2: 5.375016 seconds
    Time for relu2: 0.004450 seconds
    Time for pool2: 0.017326 seconds
    Time for conv3: 1.716275 seconds
    Time for relu3: 0.001211 seconds
    Time for pool3: 0.004333 seconds
    Time for fc: 0.005578 seconds
    Time for softmax: 0.000417 seconds

  Conv: 11.319739 seconds
  ReLU: 0.020329 seconds
  Pool: 0.074615 seconds
  FC:   0.005578 seconds
  Softmax: 0.000417 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000022 seconds
Free memory time:0.001491 seconds
Total time:11.681861 seconds
END!
```

### with Reduction
```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     61, Generating present(l[:])
         Generating copyin(X[:in_size]) [if not already present]
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(128) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     80, Generating present(l[:])
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang /* blockIdx.x */
         86, #pragma acc loop seq
         88, #pragma acc loop seq
         93, #pragma acc loop seq
         94, #pragma acc loop seq
         95, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     86, Loop is parallelizable
     88, Loop is parallelizable
     93, Loop is parallelizable
     94, Loop is parallelizable
     95, Loop is parallelizable
    100, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    183, Zero trip check eliminated
fc_forward:
    238, FMA (fused multiply-add) instruction(s) generated
load_conv:
    296, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native -o cnn-cifar10 main.o layers.o malloc2D.o timer.o

$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.023128 seconds
Create Network time:0.227325 seconds
Load Network Parameters time:0.008866 seconds
Create Ouputs time:0.000033 seconds

Net Forward total time:3.827113 seconds
    Time for conv1: 2.022345 seconds
    Time for relu1: 0.015537 seconds
    Time for pool1: 0.051935 seconds
    Time for conv2: 1.283414 seconds
    Time for relu2: 0.004531 seconds
    Time for pool2: 0.016871 seconds
    Time for conv3: 0.420664 seconds
    Time for relu3: 0.001219 seconds
    Time for pool3: 0.004199 seconds
    Time for fc: 0.005525 seconds
    Time for softmax: 0.000429 seconds

  Conv: 3.726423 seconds
  ReLU: 0.021287 seconds
  Pool: 0.073006 seconds
  FC:   0.005525 seconds
  Softmax: 0.000429 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000041 seconds
Free memory time:0.001771 seconds
Total time:4.088277 seconds
END!
```

#### Profiling
##### nvporof

```
$ nvprof ./cnn-cifar10-profile 
Parallel (pad) Code
CNN for 1200 images
Loading input batch 1...
Load Data time:0.022038 seconds
==3409405== NVPROF is profiling process 3409405, command: ./cnn-cifar10-profile
Create Network time:0.480850 seconds
Load Network Parameters time:0.008305 seconds
Create Ouputs time:0.000038 seconds

Net Forward total time:3.934778 seconds
    Time for conv1: 2.071898 seconds
    Time for relu1: 0.017331 seconds
    Time for pool1: 0.038384 seconds
    Time for conv2: 1.321276 seconds
    Time for relu2: 0.004870 seconds
    Time for pool2: 0.013281 seconds
    Time for conv3: 0.456898 seconds
    Time for relu3: 0.001509 seconds
    Time for pool3: 0.003146 seconds
    Time for fc: 0.005198 seconds
    Time for softmax: 0.000381 seconds

  Conv: 3.850072 seconds
  ReLU: 0.023709 seconds
  Pool: 0.054811 seconds
  FC:   0.005198 seconds
  Softmax: 0.000381 seconds

Net Accuracy: 78.25 % 
Net Accuracy time:0.000037 seconds
Free memory time:0.002263 seconds
Total time:4.448310 seconds
END!
==3409405== Profiling application: ./cnn-cifar10-profile
==3409405== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   99.20%  3.54577s      3600  984.94us  308.38us  1.7994ms  _8layers_c_conv_forward_80_gpu
                    0.31%  11.198ms      3600  3.1100us  2.9110us  13.056us  _8layers_c_pad_input_61_gpu
                    0.30%  10.716ms      3600  2.9760us  1.3430us  18.272us  [CUDA memcpy DtoH]
                    0.19%  6.6946ms      3630  1.8440us     640ns  5.7920us  [CUDA memcpy HtoD]
      API calls:   91.16%  3.60438s     18012  200.11us  1.0550us  2.9888ms  cuStreamSynchronize
                    4.04%  159.88ms         1  159.88ms  159.88ms  159.88ms  cuDevicePrimaryCtxRetain
                    1.61%  63.481ms      3600  17.633us  10.521us  745.61us  cuMemcpyDtoHAsync
                    1.02%  40.420ms         1  40.420ms  40.420ms  40.420ms  cuMemHostAlloc
                    1.00%  39.527ms      3630  10.889us  2.6820us  336.33us  cuMemcpyHtoDAsync
                    0.81%  31.911ms      7200  4.4320us  3.7390us  54.447us  cuLaunchKernel
                    0.17%  6.8244ms     14400     473ns     180ns  788.09us  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.10%  3.8186ms        18  212.14us  2.4450us  3.7306ms  cuMemAlloc
                    0.03%  1.3586ms         1  1.3586ms  1.3586ms  1.3586ms  cuMemAllocHost
                    0.03%  1.1783ms      7209     163ns     124ns  11.428us  cuDeviceGetAttribute
                    0.02%  718.64us      1217     590ns     331ns  23.463us  cuPointerGetAttributes
                    0.01%  265.95us         1  265.95us  265.95us  265.95us  cuModuleLoadDataEx
                    0.00%  15.822us         2  7.9110us     657ns  15.165us  cuModuleGetFunction
                    0.00%  10.252us         1  10.252us  10.252us  10.252us  cuDeviceGetPCIBusId
                    0.00%  3.1790us         3  1.0590us     223ns  1.6250us  cuCtxSetCurrent
                    0.00%  1.7630us         3     587ns     111ns  1.4760us  cuDeviceGetCount
                    0.00%     658ns         2     329ns     158ns     500ns  cuDeviceGet
                    0.00%     583ns         3     194ns     123ns     304ns  cuDriverGetVersion
                    0.00%     519ns         1     519ns     519ns     519ns  cuCtxGetCurrent
                    0.00%     475ns         1     475ns     475ns     475ns  cuDeviceComputeCapability
 OpenACC (excl):   91.88%  3.56870s      7200  495.65us  1.6720us  3.0467ms  acc_wait@layers.c:80
                    1.71%  66.599ms      3600  18.499us  11.259us  747.19us  acc_enqueue_download@layers.c:108 (Y[:l->out_size])
                    1.09%  42.253ms      3600  11.736us  4.3730us  337.18us  acc_enqueue_upload@layers.c:61 (X[:in_size])
                    1.08%  41.932ms      7200  5.8230us  2.0990us  1.1268ms  acc_wait@layers.c:61
                    1.05%  40.840ms         9  4.5378ms  11.880us  40.540ms  acc_enter_data@layers.c:42
                    0.58%  22.384ms      3600  6.2170us  4.9990us  738.56us  acc_enqueue_launch@layers.c:61 (_8layers_c_pad_input_61_gpu)
                    0.48%  18.750ms      3600  5.2080us  4.6840us  21.521us  acc_enqueue_launch@layers.c:80 (_8layers_c_conv_forward_80_gpu)
                    0.40%  15.675ms      3600  4.3540us  3.2380us  1.1455ms  acc_enter_data@layers.c:61
                    0.37%  14.364ms      3600  3.9900us  2.7410us  780.30us  acc_exit_data@layers.c:80
                    0.35%  13.431ms      3600  3.7300us  2.4710us  764.43us  acc_compute_construct@layers.c:80
                    0.32%  12.581ms      3600  3.4940us  2.5750us  791.79us  acc_compute_construct@layers.c:61
                    0.25%  9.8228ms      3600  2.7280us  2.4550us  19.159us  acc_enter_data@layers.c:80
                    0.20%  7.8607ms      3600  2.1830us  1.9580us  21.515us  acc_exit_data@layers.c:61
                    0.18%  7.1386ms      3600  1.9820us  1.7700us  19.938us  acc_wait@layers.c:108
                    0.02%  869.10us        18  48.283us     904ns  782.98us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.01%  341.22us         1  341.22us  341.22us  341.22us  acc_device_init@layers.c:42
                    0.00%  98.543us        18  5.4740us     821ns  35.573us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.00%  60.782us         9  6.7530us  4.5420us  11.631us  acc_wait@layers.c:42
                    0.00%  46.753us         9  5.1940us  1.7500us  20.309us  acc_exit_data@layers.c:53
                    0.00%  42.868us         3  14.289us  8.2590us  18.757us  acc_enqueue_upload@layers.c:296 (l->weights[:l->weights_size])
                    0.00%  39.688us         3  13.229us  4.5530us  30.539us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.00%  32.545us         3  10.848us  7.7080us  12.869us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.00%  20.927us         3  6.9750us  3.4980us  9.1530us  acc_wait@layers.c:296
                    0.00%  15.441us         3  5.1470us  3.1250us  8.9870us  acc_update@layers.c:296
                    0.00%  11.152us         3  3.7170us  3.4970us  3.8440us  acc_enqueue_upload@layers.c:296 (l->bias[:l->out_depth])
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:80
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:61
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_create@layers.c:80
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_create@layers.c:61
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_delete@layers.c:73
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
                    0.00%       0ns      3600       0ns       0ns       0ns  acc_delete@layers.c:108
```
## Pad 50k
### code
```c
60:
void pad_input(float* restrict X, Conv_Layer* l) {
#pragma acc parallel loop present(l,X) 
  for ( int c = 0; c < l->in_depth; c++) {
    #pragma acc loop independent
    for (int j = 0; j < l->in_height; j++) {
      #pragma acc loop independent
      for (int i = 0; i < l->in_width; i++) {
        // ...


78:
void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  int in_size = l->in_width*l->in_height*l->in_depth;
#pragma acc data copyin(X[0:in_size]) copyout(Y[0:l->out_size]) present(l)
  {
    pad_input(X, l); //Create input with zero-padding
   // For each output feature map
#pragma acc parallel loop present(l,X,Y)
    for ( int m = 0; m < l->out_depth; m++) {
      #pragma acc loop independent
      for (int j = 0; j < l->out_height; j++) {
        #pragma acc loop independent
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
        #pragma acc loop  reduction(+:sum)
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
```

### Minfo
```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     60, Generating present(X[:],l[:])
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         62, #pragma acc loop gang /* blockIdx.x */
         64, #pragma acc loop seq
         66, #pragma acc loop vector(128) /* threadIdx.x */
     64, Loop is parallelizable
     66, Loop is parallelizable
conv_forward:
     81, Generating copyin(X[:in_size]) [if not already present]
         Generating copyout(Y[:l->out_size]) [if not already present]
         Generating present(l[:])
     82, Generating present(l[:],Y[:],X[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         85, #pragma acc loop gang /* blockIdx.x */
         87, #pragma acc loop seq
         89, #pragma acc loop seq
         94, #pragma acc loop seq
         95, #pragma acc loop seq
         96, #pragma acc loop vector(128) /* threadIdx.x */
             Generating reduction(+:sum)
     87, Loop is parallelizable
     89, Loop is parallelizable
     94, Loop is parallelizable
     95, Loop is parallelizable
     96, Loop is parallelizable
    101, FMA (fused multiply-add) instruction(s) generated
pool_forward:
    184, Zero trip check eliminated
fc_forward:
    239, FMA (fused multiply-add) instruction(s) generated
load_conv:
    300, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

### execution
```
$ ./cnn-cifar10 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.922217 seconds
Create Network time:0.256042 seconds
Load Network Parameters time:0.044504 seconds
Create Ouputs time:0.000403 seconds

Net Forward total time:157.489354 seconds
    Time for conv1: 83.147804 seconds
    Time for relu1: 0.504927 seconds
    Time for pool1: 2.022948 seconds
    Time for conv2: 53.128675 seconds
    Time for relu2: 0.155501 seconds
    Time for pool2: 0.659966 seconds
    Time for conv3: 17.397355 seconds
    Time for relu3: 0.045444 seconds
    Time for pool3: 0.164105 seconds
    Time for fc: 0.217070 seconds
    Time for softmax: 0.023882 seconds

  Conv: 153.673834 seconds
  ReLU: 0.705872 seconds
  Pool: 2.847019 seconds
  FC:   0.217070 seconds
  Softmax: 0.023882 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.001368 seconds
Free memory time:0.040154 seconds
Total time:158.754041 seconds
END!
```

### Profiling
#### nvprof

```
$ nvprof ./cnn-cifar10-profile 
Parallel (pad) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.763341 seconds
==3131715== NVPROF is profiling process 3131715, command: ./cnn-cifar10-profile
Create Network time:0.533695 seconds
Load Network Parameters time:0.008640 seconds
Create Ouputs time:0.000350 seconds

Net Forward total time:162.044456 seconds
    Time for conv1: 84.843385 seconds
    Time for relu1: 0.686628 seconds
    Time for pool1: 1.601398 seconds
    Time for conv2: 54.708089 seconds
    Time for relu2: 0.204118 seconds
    Time for pool2: 0.531737 seconds
    Time for conv3: 19.012389 seconds
    Time for relu3: 0.057542 seconds
    Time for pool3: 0.132855 seconds
    Time for fc: 0.218862 seconds
    Time for softmax: 0.016533 seconds

  Conv: 158.563863 seconds
  ReLU: 0.948288 seconds
  Pool: 2.265990 seconds
  FC:   0.218862 seconds
  Softmax: 0.016533 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.001300 seconds
Free memory time:0.041859 seconds
Total time:163.393641 seconds
END!
==3131715== Profiling application: ./cnn-cifar10-profile
==3131715== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   99.19%  146.132s    150000  974.21us  307.39us  1.7892ms  _8layers_c_conv_forward_82_gpu
                    0.32%  464.21ms    150000  3.0940us  2.8790us  13.568us  _8layers_c_pad_input_60_gpu
                    0.30%  446.98ms    150000  2.9790us  1.3430us  18.368us  [CUDA memcpy DtoH]
                    0.19%  276.48ms    150030  1.8420us     672ns  5.7910us  [CUDA memcpy HtoD]
      API calls:   96.45%  148.174s    900012  164.64us     579ns  4.0498ms  cuStreamSynchronize
                    1.69%  2.59074s    150000  17.271us  10.338us  2.0757ms  cuMemcpyDtoHAsync
                    0.79%  1.22025s    300000  4.0670us  3.1190us  1.1529ms  cuLaunchKernel
                    0.76%  1.17456s    150030  7.8280us  2.8200us  1.1561ms  cuMemcpyHtoDAsync
                    0.12%  180.76ms    600000     301ns     180ns  1.3824ms  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    0.10%  147.81ms         1  147.81ms  147.81ms  147.81ms  cuDevicePrimaryCtxRetain
                    0.04%  59.195ms    300009     197ns     124ns  672.37us  cuDeviceGetAttribute
                    0.03%  42.314ms         1  42.314ms  42.314ms  42.314ms  cuMemHostAlloc
                    0.02%  26.111ms     50020     522ns     347ns  31.947us  cuPointerGetAttributes
                    0.01%  11.351ms         2  5.6754ms     719ns  11.350ms  cuModuleGetFunction
                    0.00%  3.1803ms        19  167.38us  2.8350us  3.0780ms  cuMemAlloc
                    0.00%  1.4343ms         1  1.4343ms  1.4343ms  1.4343ms  cuMemAllocHost
                    0.00%  292.23us         1  292.23us  292.23us  292.23us  cuModuleLoadDataEx
                    0.00%  6.9250us         1  6.9250us  6.9250us  6.9250us  cuDeviceGetPCIBusId
                    0.00%  6.2280us         1  6.2280us  6.2280us  6.2280us  cuCtxGetCurrent
                    0.00%  3.2020us         3  1.0670us     191ns  1.5090us  cuCtxSetCurrent
                    0.00%  2.3440us         3     781ns     176ns  1.9480us  cuDeviceGetCount
                    0.00%     747ns         3     249ns     143ns     431ns  cuDriverGetVersion
                    0.00%     712ns         2     356ns     156ns     556ns  cuDeviceGet
                    0.00%     422ns         1     422ns     422ns     422ns  cuDeviceComputeCapability
 OpenACC (excl):   92.89%  146.887s    300000  489.62us  1.6810us  4.0517ms  acc_wait@layers.c:82
                    1.73%  2.73116s    150000  18.207us  11.095us  2.0772ms  acc_enqueue_download@layers.c:110 (Y[:l->out_size])
                    0.83%  1.30743s    150000  8.7160us  4.3320us  1.1577ms  acc_enqueue_upload@layers.c:81 (X[:in_size])
                    0.67%  1.06279s    300000  3.5420us  1.1810us  993.27us  acc_wait@layers.c:60
                    0.55%  874.92ms    150000  5.8320us  4.7630us  1.1861ms  acc_enter_data@layers.c:81
                    0.55%  870.43ms    150000  5.8020us  4.7730us  886.52us  acc_enqueue_launch@layers.c:60 (_8layers_c_pad_input_60_gpu)
                    0.44%  699.24ms    150000  4.6610us  4.0120us  1.1544ms  acc_enqueue_launch@layers.c:82 (_8layers_c_conv_forward_82_gpu)
                    0.43%  674.18ms    150000  4.4940us  3.5500us  837.81us  acc_exit_data@layers.c:81
                    0.38%  607.72ms    150000  4.0510us  2.0320us  758.11us  acc_wait@layers.c:81
                    0.29%  455.12ms    150000  3.0340us  2.5760us  1.4108ms  acc_compute_construct@layers.c:60
                    0.28%  450.60ms    150000  3.0040us  2.3480us  1.1867ms  acc_compute_construct@layers.c:82
                    0.21%  337.00ms    150000  2.2460us  1.7420us  839.48us  acc_wait@layers.c:110
                    0.19%  304.33ms    150000  2.0280us  1.7910us  1.1361ms  acc_enter_data@layers.c:82
                    0.18%  287.32ms    150000  1.9150us  1.4540us  802.86us  acc_enter_data@layers.c:60
                    0.18%  278.76ms    150000  1.8580us  1.5330us  23.828us  acc_exit_data@layers.c:82
                    0.16%  255.43ms    150000  1.7020us  1.2950us  791.98us  acc_exit_data@layers.c:60
                    0.03%  42.772ms         9  4.7524ms  10.905us  42.445ms  acc_enter_data@layers.c:42
                    0.00%  355.40us         1  355.40us  355.40us  355.40us  acc_device_init@layers.c:42
                    0.00%  99.990us         9  11.110us  4.4850us  37.630us  acc_wait@layers.c:42
                    0.00%  84.463us        18  4.6920us     942ns  24.693us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.00%  63.897us        18  3.5490us     877ns  22.227us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.00%  47.547us         3  15.849us  4.7730us  33.747us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.00%  43.787us         9  4.8650us  1.7250us  18.546us  acc_exit_data@layers.c:53
                    0.00%  42.092us         3  14.030us  7.9530us  18.942us  acc_enqueue_upload@layers.c:300 (l->weights[:l->weights_size])
                    0.00%  31.988us         3  10.662us  8.1580us  13.319us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.00%  21.987us         3  7.3290us  3.9460us  9.5190us  acc_wait@layers.c:300
                    0.00%  13.203us         3  4.4010us  2.9020us  7.0810us  acc_update@layers.c:300
                    0.00%  12.310us         3  4.1030us  3.6690us  4.7190us  acc_enqueue_upload@layers.c:300 (l->bias[:l->out_depth])
                    0.00%       0ns    300000       0ns       0ns       0ns  acc_delete@layers.c:110
                    0.00%       0ns         6       0ns       0ns       0ns  acc_alloc@layers.c:81
                    0.00%       0ns    300000       0ns       0ns       0ns  acc_create@layers.c:81
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
```

