# Full forward on GPU


```c
File: layers.c
...
060: void pad_input(float* restrict X, Conv_Layer* l) {
061: 
062: #pragma acc parallel loop present(l,X)  gang vector_length(32)
063:   for (int c = 0; c < l->in_depth; c++) {
064:   #pragma acc loop 
065:     for (int j = 0; j < l->in_height; j++) {
066:     #pragma acc loop vector
067:       for (int i = 0; i < l->in_width; i++) {
068:         int padded_idx = (j + l->padding) * l->padded_width + (i + l->padding) + c * l->padded_height * l->padded_width;
069:         int in_idx = j * l->in_width + i + c * l->in_height * l->in_width;
070:         l->in_padded[padded_idx] = X[in_idx];
071:       }
072:     }
073:   }
074: }
...
079: void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
080: 
081:   pad_input(X, l); //Create input with zero-padding
082:   // For each output feature map
083: #pragma acc parallel loop present(l,Y) gang worker collapse(3) vector_length(32)
084:   for (int m = 0; m < l->out_depth; m++) {
085:     for (int j = 0; j < l->out_height; j++) {
086:       for (int i = 0; i < l->out_width; i++) {
087:         int y_idx = i + (l->out_width * (j + m * l->out_height)); // Output index
088:         // Calculate dot product of Weights*Input
089:         float sum = 0.0f;
090:       #pragma acc loop reduction(+:sum) vector collapse(2) 
091:         for (int c = 0; c < l->in_depth; c++) {
092:           for (int f_j = 0; f_j < l->filter_width; f_j++) {
093:             for (int f_i = 0; f_i < l->filter_width; f_i++) {
094:               int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); // Filter Index
095:               int x_j = j * l->stride + f_j; // Input height index, increased by stride
096:               int x_i = i * l->stride + f_i; // Input width index, increased by stride
097:               int x_idx = c * l->padded_height * l->padded_width + x_j * l->padded_width + x_i; // Input index
098:               sum += l->weights[f_idx] * l->in_padded[x_idx];
099:             } // for f_i
100:           } // for f_j
101:         } // for c
102:         sum += l->bias[m]; // Add bias
103:         Y[y_idx] = sum; // Save output result
104:       } // for i
105:     } // for j
106:   } // for m
107: }
108: 
...
135: void relu_forward(float* restrict X, ReLU_Layer* l, float* restrict Y) {
136: 
137: #pragma acc parallel loop present(l,X,Y) gang vector vector_length(32)
138:   for (int i = 0; i < l->out_size; i++) {
139:     Y[i] = (X[i] < 0.0f) ? 0.0f : X[i];
140:   }
141: }
142: 
...
181: void pool_forward(float* restrict X, Pool_Layer* l, float* restrict Y) {
182:   // For each output feature map
183: #pragma acc parallel loop present(X,l,Y) gang worker collapse(3) vector_length(32)
184:   for (int m = 0; m < l->out_depth; m++) {
185:     for (int j = 0; j < l->out_height; j++) {
186:       for (int i = 0; i < l->out_width; i++) {
187:         int y_idx = i + l->out_width * (j + m * l->out_height); // Output index
188:         // Find Max in pooling filter
189:         float max = -INFINITY;
190:       #pragma acc loop reduction(max:max) vector collapse(2)
191:         for (int p_j = 0; p_j < l->pool_width; p_j++) {
192:           for (int p_i = 0; p_i < l->pool_width; p_i++) {
193:             int x_j = j * l->stride + p_j; // Input height index, increased by stride
194:             int x_i = i * l->stride + p_i; // Input width index, increased by stride
195:             int x_idx = x_i + (x_j + m * l->in_height) * l->in_width; // Input index
196:             if (X[x_idx] > max) {
197:               max = X[x_idx];
198:             } // if max
199:           } // for p_i
200:         } // for p_j
201:         Y[y_idx] = max;
202:       } // for i
203:     } // for j
204:   } // for m
205: }
206: 
...
247: void fc_forward(float* restrict X, FC_Layer* l, float* restrict Y) {
248: 
249:   // For every output neuron
250: #pragma acc parallel loop present(l,X,Y) gang worker vector_length(32)
251:   for (int i = 0; i < l->out_depth; i++) {
252:     // Calculate dot product of input and weights
253:     float sum = 0.0f;
254:   #pragma loop reduction(+:sum) vector
255:     for (int j = 0; j < l->in_neurons; j++) {
256:       int w_idx = j + i * l->in_neurons; // Weight index
257:       sum += X[j] * l->weights[w_idx];
258:     }
259:     sum += l->bias[i]; // add bias
260:     Y[i] = sum;
261:   }
262: }
...
...
405: void softmax_forward(float* restrict X, Softmax_Layer* l, float* restrict Y) {
406: 
407:   float max = -INFINITY;
408:   float total = 0.0f;
409: 
410: #pragma acc data present(X,l,Y) create(max,total) cache(X[0:10])
411:   {
412:     // Compute max activation
413:   #pragma acc parallel loop reduction(max:max) vector vector_length(32)
414:     for (int i = 0; i < l->out_depth; i++) {
415:       if (X[i] > max) {
416:         max = X[i];
417:       }
418:     }
419: 
420:     // Compute exponentials and total
421:   #pragma acc parallel loop reduction(+:total) vector vector_length(32)
422:     for (int i = 0; i < l->out_depth; i++) {
423:       float e = exp(X[i] - max);
424:       total += e;
425:       l->likelihoods[i] = e;
426:     }
427: 
428:     // Normalize and output to sum to one
429:   #pragma acc parallel loop vector vector_length(32)
430:     for (int i = 0; i < l->out_depth; i++) {
431:       Y[i] = l->likelihoods[i] / total;
432:     }
433:   }
434: }
...
447: 
```

best opts:
 **Use vector length 32, because GPU warp size is 32.**

```
$ make
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
make_conv_layer:
     42, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->weights_size])
         Generating enter data copyin(layer->in_padded[:layer->padded_size])
         Generating enter data create(layer->bias[:M])
free_conv:
     53, Generating exit data delete(l->bias[:l->out_depth],l->in_padded[:l->padded_size],l[:1],l->weights[:l->weights_size])
pad_input:
     60, Generating present(X[:],l[:])
         Generating implicit firstprivate(c)
         Generating NVIDIA GPU code
         63, #pragma acc loop gang /* blockIdx.x */
         65, #pragma acc loop seq
         67, #pragma acc loop vector(32) /* threadIdx.x */
     65, Loop is parallelizable
     67, Loop is parallelizable
conv_forward:
     81, Generating present(l[:],Y[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
         84, #pragma acc loop gang, worker(4) collapse(3) /* blockIdx.x threadIdx.y */
         85,   /* blockIdx.x threadIdx.y collapsed */
         86,   /* blockIdx.x threadIdx.y collapsed */
         91, #pragma acc loop vector(32) collapse(2) /* threadIdx.x */
             Generating reduction(+:sum)
         92,   /* threadIdx.x collapsed */
         93, #pragma acc loop seq
        100, Vector barrier inserted for vector loop reduction
             Vector barrier inserted due to potential dependence out of a vector loop
     91, Loop is parallelizable
     92, Loop is parallelizable
     93, Loop is parallelizable
     98, FMA (fused multiply-add) instruction(s) generated
make_relu_layer:
    130, Generating enter data copyin(layer[:1])
relu_forward:
    135, Generating present(Y[:],l[:],X[:])
         Generating implicit firstprivate(i)
         Generating NVIDIA GPU code
        138, #pragma acc loop gang, vector(32) /* blockIdx.x threadIdx.x */
free_relu:
    148, Generating exit data delete(l[:1])
make_pool_layer:
    176, Generating enter data copyin(layer[:1])
pool_forward:
    181, Generating present(l[:],Y[:],X[:])
         Generating implicit firstprivate(m)
         Generating NVIDIA GPU code
        184, #pragma acc loop gang, worker(4) collapse(3) /* blockIdx.x threadIdx.y */
        185,   /* blockIdx.x threadIdx.y collapsed */
        186,   /* blockIdx.x threadIdx.y collapsed */
        191, #pragma acc loop vector(32) collapse(2) /* threadIdx.x */
             Generating reduction(max:max)
        192,   /* threadIdx.x collapsed */
        199, Vector barrier inserted for vector loop reduction
             Vector barrier inserted due to potential dependence out of a vector loop
    191, Loop is parallelizable
    192, Loop is parallelizable
free_pool:
    212, Generating exit data delete(l[:1])
make_fc_layer:
    242, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->weights[:layer->out_depth*layer->in_neurons],layer->bias[:layer->out_depth])
fc_forward:
    247, Generating present(l[:],Y[:],X[:])
         Generating implicit firstprivate(i)
         Generating NVIDIA GPU code
        251, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */
        255, #pragma acc loop vector(32) /* threadIdx.x */
             Generating implicit reduction(+:sum)
        257, Vector barrier inserted for vector loop reduction
    255, Loop is parallelizable
    257, FMA (fused multiply-add) instruction(s) generated
free_fc:
    273, Generating exit data delete(l->bias[:l->out_depth],l[:1],l->weights[:l->out_depth*l->in_neurons])
load_conv:
    322, Generating update device(l->weights[:l->weights_size],l->bias[:l->out_depth])
load_fc:
    373, Generating update device(l->weights[:l->out_depth*l->in_neurons],l->bias[:l->out_depth])
make_softmax_layer:
    400, Generating enter data copyin(layer[:1])
         Generating enter data create(layer->likelihoods[:layer->out_depth])
softmax_forward:
    411, Generating present(l[:],Y[:],X[:])
         Generating create(total,max) [if not already present]
         Generating implicit firstprivate(i)
         Generating NVIDIA GPU code
        414, #pragma acc loop vector(32) /* threadIdx.x */
             Generating reduction(max:max)
    414, Loop is parallelizable
    418, Generating implicit firstprivate(i)
         Generating NVIDIA GPU code
        422, #pragma acc loop vector(32) /* threadIdx.x */
             Generating reduction(+:total)
    422, Loop is parallelizable
    426, Generating implicit firstprivate(i)
         Generating NVIDIA GPU code
        430, #pragma acc loop vector(32) /* threadIdx.x */
    430, Loop is parallelizable
free_softmax:
    444, Generating exit data delete(l[:1],l->likelihoods[:l->out_depth])
nvc -acc -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
olia@krylov100:~/Diplomatiki/cnn-cifar10_0/serial2parallel-4$ ./cnn-cifar10 
Parallel Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.678608 seconds
Create Network time:0.169604 seconds
Load Network Parameters time:0.007930 seconds
Create Ouputs time:0.000318 seconds

Net Forward total time:11.058935 seconds
    Time for conv1: 2.078987 seconds
    Time for relu1: 0.680793 seconds
    Time for pool1: 0.679397 seconds
    Time for conv2: 1.854469 seconds
    Time for relu2: 0.679914 seconds
    Time for pool2: 0.567739 seconds
    Time for conv3: 1.384512 seconds
    Time for relu3: 0.683641 seconds
    Time for pool3: 0.524825 seconds
    Time for fc: 0.566316 seconds
    Time for softmax: 1.339671 seconds

  Conv: 5.317968 seconds
  ReLU: 2.044347 seconds
  Pool: 1.771961 seconds
  FC:   0.566316 seconds
  Softmax: 1.339671 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000804 seconds
Free memory time:0.046795 seconds
Total time:11.962994 seconds
END!
```

### nvprof

```
$ nvprof ./cnn-cifar10-profile 
Parallel Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.708388 seconds
==2151530== NVPROF is profiling process 2151530, command: ./cnn-cifar10-profile
Create Network time:0.552162 seconds
Load Network Parameters time:0.008110 seconds
Create Ouputs time:0.000312 seconds

Net Forward total time:18.812495 seconds
    Time for conv1: 3.170638 seconds
    Time for relu1: 1.193030 seconds
    Time for pool1: 1.172006 seconds
    Time for conv2: 2.895355 seconds
    Time for relu2: 1.190618 seconds
    Time for pool2: 1.036300 seconds
    Time for conv3: 2.381009 seconds
    Time for relu3: 1.180804 seconds
    Time for pool3: 1.008425 seconds
    Time for fc: 1.052947 seconds
    Time for softmax: 2.504704 seconds

  Conv: 8.447002 seconds
  ReLU: 3.564453 seconds
  Pool: 3.216731 seconds
  FC:   1.052947 seconds
  Softmax: 2.504704 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000715 seconds
Free memory time:0.060942 seconds
Total time:20.143123 seconds
END!
==2151530== Profiling application: ./cnn-cifar10-profile
==2151530== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   43.60%  2.48818s    150000  16.587us  7.8400us  25.184us  _8layers_c_conv_forward_81_gpu
                   16.07%  917.28ms    150000  6.1150us  6.0480us  13.568us  _8layers_c_pad_input_60_gpu
                   16.04%  915.74ms    150000  6.1040us  6.0150us  13.600us  _8layers_c_relu_forward_135_gpu
                   11.78%  672.14ms    150000  4.4800us  3.0710us  13.535us  _8layers_c_pool_forward_181_gpu
                    3.29%  187.96ms     50000  3.7590us  3.6790us  13.600us  _8layers_c_fc_forward_247_gpu
                    2.61%  149.21ms     50000  2.9840us  2.9430us  13.376us  _8layers_c_softmax_forward_418_gpu
                    2.42%  138.27ms        47  2.9419ms     735ns  138.22ms  [CUDA memcpy HtoD]
                    2.33%  132.74ms     50000  2.6540us  2.6230us  13.184us  _8layers_c_softmax_forward_411_gpu
                    1.85%  105.74ms     50000  2.1140us  2.0790us  13.568us  _8layers_c_softmax_forward_426_gpu
                    0.00%  156.80us         1  156.80us  156.80us  156.80us  [CUDA memcpy DtoH]
                    0.00%  5.0560us         2  2.5280us  2.4320us  2.6240us  _21______src_cuda_fill_c___pgi_uacc_cuda_fill_44_gpu
      API calls:   68.09%  8.21022s   1500030  5.4730us  1.0270us  3.4470ms  cuStreamSynchronize
                   25.31%  3.05226s    800002  3.8150us  3.2100us  4.7466ms  cuLaunchKernel
                    2.53%  305.47ms   1000000     305ns     182ns  4.1102ms  cuOccupancyMaxActiveBlocksPerMultiprocessor
                    1.34%  161.44ms         1  161.44ms  161.44ms  161.44ms  cuDevicePrimaryCtxRetain
                    1.15%  138.66ms        47  2.9503ms  2.5230us  138.39ms  cuMemcpyHtoDAsync
                    0.88%  106.70ms    800011     133ns     113ns  16.810us  cuDeviceGetAttribute
                    0.39%  47.470ms         1  47.470ms  47.470ms  47.470ms  cuMemHostAlloc
                    0.25%  30.382ms    100039     303ns     229ns  778.75us  cuPointerGetAttributes
                    0.02%  1.9363ms         1  1.9363ms  1.9363ms  1.9363ms  cuMemcpyDtoHAsync
                    0.01%  1.2867ms         2  643.37us  128.20us  1.1585ms  cuModuleLoadDataEx
                    0.01%  1.2860ms         1  1.2860ms  1.2860ms  1.2860ms  cuMemAllocHost
                    0.01%  868.68us        40  21.717us  1.8670us  225.54us  cuMemAlloc
                    0.00%  17.957us        10  1.7950us     355ns  11.310us  cuModuleGetFunction
                    0.00%  10.051us         1  10.051us  10.051us  10.051us  cuDeviceGetPCIBusId
                    0.00%  2.8780us         3     959ns     208ns  1.8370us  cuCtxSetCurrent
                    0.00%  1.4040us         3     468ns     142ns  1.0260us  cuDeviceGetCount
                    0.00%     978ns         3     326ns     121ns     618ns  cuDriverGetVersion
                    0.00%     598ns         2     299ns     158ns     440ns  cuDeviceGet
                    0.00%     507ns         1     507ns     507ns     507ns  cuCtxGetCurrent
                    0.00%     394ns         1     394ns     394ns     394ns  cuDeviceComputeCapability
 OpenACC (excl):  100.00%  1.7e+10s         5  3.3e+09s  15.582us  1.7e+10s  acc_enter_data@main.c:180
                    0.00%  3.19692s    300000  10.656us  1.6090us  1.7577ms  acc_wait@layers.c:81
                    0.00%  1.63793s    300000  5.4590us  1.6280us  751.36us  acc_wait@layers.c:60
                    0.00%  1.62830s    300000  5.4270us  1.5990us  754.48us  acc_wait@layers.c:135
                    0.00%  1.38833s    300000  4.6270us  1.6170us  791.54us  acc_wait@layers.c:181
                    0.00%  764.89ms    150000  5.0990us  4.1290us  4.7544ms  acc_enqueue_launch@layers.c:135 (_8layers_c_relu_forward_135_gpu)
                    0.00%  756.05ms    150000  5.0400us  4.1380us  823.95us  acc_enqueue_launch@layers.c:81 (_8layers_c_conv_forward_81_gpu)
                    0.00%  751.70ms    150000  5.0110us  4.1500us  843.31us  acc_enqueue_launch@layers.c:60 (_8layers_c_pad_input_60_gpu)
                    0.00%  735.67ms    150000  4.9040us  4.2900us  2.7132ms  acc_enqueue_launch@layers.c:181 (_8layers_c_pool_forward_181_gpu)
                    0.00%  422.76ms    100000  4.2270us  1.6190us  121.24us  acc_wait@layers.c:247
                    0.00%  412.20ms    150000  2.7480us  2.3620us  847.53us  acc_compute_construct@layers.c:60
                    0.00%  395.55ms    150000  2.6360us  2.3850us  4.5780ms  acc_compute_construct@layers.c:81
                    0.00%  394.00ms    150000  2.6260us  2.3450us  4.2655ms  acc_compute_construct@layers.c:135
                    0.00%  366.14ms    100000  3.6610us  1.6900us  23.227us  acc_wait@layers.c:411
                    0.00%  348.36ms    150000  2.3220us  1.6890us  845.29us  acc_enter_data@layers.c:135
                    0.00%  323.33ms    150000  2.1550us  1.4920us  1.5173ms  acc_exit_data@layers.c:181
                    0.00%  304.97ms    150000  2.0330us  1.5860us  828.91us  acc_compute_construct@layers.c:181
                    0.00%  295.28ms    150000  1.9680us  1.3770us  798.56us  acc_enter_data@layers.c:81
                    0.00%  295.05ms     50000  5.9000us  1.9780us  23.807us  acc_wait@layers.c:418
                    0.00%  292.40ms    150000  1.9490us  1.6820us  21.205us  acc_enter_data@layers.c:181
                    0.00%  257.04ms    150000  1.7130us  1.5230us  736.27us  acc_exit_data@layers.c:135
                    0.00%  256.85ms     50000  5.1370us  4.2690us  2.1072ms  acc_enter_data@layers.c:411
                    0.00%  252.94ms     50000  5.0580us  4.1530us  824.33us  acc_enqueue_launch@layers.c:247 (_8layers_c_fc_forward_247_gpu)
                    0.00%  252.76ms     50000  5.0550us  1.9700us  3.4572ms  acc_wait@layers.c:426
                    0.00%  246.06ms     50000  4.9210us  4.4230us  755.65us  acc_enqueue_launch@layers.c:411 (_8layers_c_softmax_forward_411_gpu)
                    0.00%  238.56ms    150000  1.5900us  1.3700us  448.34us  acc_enter_data@layers.c:60
                    0.00%  231.98ms     50000  4.6390us  4.1690us  1.4692ms  acc_enqueue_launch@layers.c:426 (_8layers_c_softmax_forward_426_gpu)
                    0.00%  231.06ms     50000  4.6210us  4.1440us  750.47us  acc_enqueue_launch@layers.c:418 (_8layers_c_softmax_forward_418_gpu)
                    0.00%  217.10ms    150000  1.4470us  1.2570us  805.10us  acc_exit_data@layers.c:60
                    0.00%  209.56ms    150000  1.3970us  1.2410us  30.138us  acc_exit_data@layers.c:81
                    0.00%  206.04ms     50000  4.1200us  3.4040us  791.42us  acc_exit_data@layers.c:411
                    0.00%  138.40ms         1  138.40ms  138.40ms  138.40ms  acc_enqueue_upload@main.c:180 (input[:50000][:3072])
                    0.00%  131.51ms     50000  2.6300us  2.3970us  744.63us  acc_compute_construct@layers.c:247
                    0.00%  110.40ms     50000  2.2070us  1.5870us  832.03us  acc_compute_construct@layers.c:411
                    0.00%  103.67ms     50000  2.0730us  1.4910us  792.18us  acc_compute_construct@layers.c:426
                    0.00%  102.72ms     50000  2.0540us  1.5000us  1.0420ms  acc_compute_construct@layers.c:418
                    0.00%  97.677ms     50000  1.9530us  1.7720us  27.139us  acc_enter_data@layers.c:247
                    0.00%  89.462ms     50000  1.7890us  1.5970us  803.66us  acc_exit_data@layers.c:247
                    0.00%  47.971ms         9  5.3301ms  11.743us  47.636ms  acc_enter_data@layers.c:42
                    0.00%  2.5555ms         5  511.09us  4.1290us  1.4696ms  acc_exit_data@main.c:235
                    0.00%  1.9399ms         1  1.9399ms  1.9399ms  1.9399ms  acc_enqueue_download@main.c:235 (O11[:50000][:L11->out_size])
                    0.00%  1.2489ms         1  1.2489ms  1.2489ms  1.2489ms  acc_device_init@layers.c:42
                    0.00%  87.051us         5  17.410us  1.7990us  75.761us  acc_wait@main.c:180
                    0.00%  83.691us        18  4.6490us     834ns  29.095us  acc_enqueue_upload@layers.c:42 (.attach.)
                    0.00%  66.121us         9  7.3460us  4.5610us  11.772us  acc_wait@layers.c:42
                    0.00%  62.375us         2  31.187us  31.089us  31.286us  acc_enqueue_launch@(runtime):44 (_21______src_cuda_fill_c___pgi_uacc_cuda_fill_44_gpu)
                    0.00%  53.065us         3  17.688us  3.7450us  45.495us  acc_enqueue_upload@layers.c:42 (layer[:1])
                    0.00%  45.966us        18  2.5530us     872ns  6.2580us  acc_enqueue_upload@layers.c:53 (.detach.)
                    0.00%  41.965us         3  13.988us  7.1460us  18.644us  acc_enqueue_upload@layers.c:322 (l->weights[:l->weights_size])
                    0.00%  41.203us         3  13.734us  12.859us  14.275us  acc_enter_data@layers.c:130
                    0.00%  37.953us         9  4.2170us  1.5440us  13.187us  acc_exit_data@layers.c:53
                    0.00%  34.092us         3  11.364us  11.036us  11.870us  acc_enter_data@layers.c:176
                    0.00%  32.026us         3  10.675us  9.7430us  11.235us  acc_enter_data@layers.c:242
                    0.00%  30.496us         3  10.165us  7.8230us  11.526us  acc_enqueue_upload@layers.c:42 (layer->in_padded[:layer->padded_size])
                    0.00%  29.168us         2  14.584us  3.0530us  26.115us  acc_enqueue_upload@layers.c:444 (.detach.)
                    0.00%  22.376us         2  11.188us  11.000us  11.376us  acc_enter_data@layers.c:400
                    0.00%  21.191us         3  7.0630us  3.3690us  9.5740us  acc_wait@layers.c:322
                    0.00%  20.686us         2  10.343us  2.4530us  18.233us  acc_exit_data@layers.c:444
                    0.00%  16.244us         3  5.4140us  4.6620us  5.8450us  acc_wait@layers.c:176
                    0.00%  16.125us         3  5.3750us  4.7190us  5.7670us  acc_wait@layers.c:130
                    0.00%  15.178us         3  5.0590us  4.8920us  5.2260us  acc_wait@layers.c:242
                    0.00%  14.871us         3  4.9570us  2.9070us  8.8500us  acc_update@layers.c:322
                    0.00%  12.999us         4  3.2490us     926ns  7.0090us  acc_enqueue_upload@layers.c:273 (.detach.)
                    0.00%  12.259us         3  4.0860us  3.6960us  4.6230us  acc_enqueue_upload@layers.c:130 (layer[:1])
                    0.00%  11.842us         3  3.9470us  3.5540us  4.5980us  acc_enqueue_upload@layers.c:322 (l->bias[:l->out_depth])
                    0.00%  11.387us         3  3.7950us  3.6860us  3.8970us  acc_enqueue_upload@layers.c:176 (layer[:1])
                    0.00%  10.195us         2  5.0970us  4.7060us  5.4890us  acc_wait@layers.c:400
                    0.00%  9.4220us         4  2.3550us     826ns  3.8910us  acc_enqueue_upload@layers.c:242 (.attach.)
                    0.00%  8.6650us         3  2.8880us  2.1130us  3.8250us  acc_exit_data@layers.c:273
                    0.00%  8.5790us         1  8.5790us  8.5790us  8.5790us  acc_enqueue_upload@layers.c:373 (l->weights[:l->out_depth*l->in_neurons])
                    0.00%  5.7230us         3  1.9070us  1.6780us  2.3020us  acc_exit_data@layers.c:148
                    0.00%  5.5110us         3  1.8370us  1.5910us  2.2090us  acc_exit_data@layers.c:212
                    0.00%  5.1500us         1  5.1500us  5.1500us  5.1500us  acc_wait@layers.c:373
                    0.00%  4.6440us         2  2.3220us     878ns  3.7660us  acc_enqueue_upload@layers.c:400 (.attach.)
                    0.00%  3.8890us         1  3.8890us  3.8890us  3.8890us  acc_wait@main.c:235
                    0.00%  3.7290us         1  3.7290us  3.7290us  3.7290us  acc_enqueue_upload@layers.c:400 (layer[:1])
                    0.00%  3.6540us         1  3.6540us  3.6540us  3.6540us  acc_enqueue_upload@layers.c:242 (layer[:1])
                    0.00%  3.2860us         1  3.2860us  3.2860us  3.2860us  acc_enqueue_upload@layers.c:373 (l->bias[:l->out_depth])
                    0.00%  3.0130us         1  3.0130us  3.0130us  3.0130us  acc_update@layers.c:373
                    0.00%       0ns         3       0ns       0ns       0ns  acc_delete@layers.c:273
                    0.00%       0ns    100000       0ns       0ns       0ns  acc_delete@layers.c:433
                    0.00%       0ns         3       0ns       0ns       0ns  acc_create@layers.c:130
                    0.00%       0ns    100000       0ns       0ns       0ns  acc_create@layers.c:411
                    0.00%       0ns         2       0ns       0ns       0ns  acc_delete@layers.c:444
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:176
                    0.00%       0ns         3       0ns       0ns       0ns  acc_delete@layers.c:212
                    0.00%       0ns        12       0ns       0ns       0ns  acc_alloc@layers.c:42
                    0.00%       0ns        12       0ns       0ns       0ns  acc_create@layers.c:42
                    0.00%       0ns        14       0ns       0ns       0ns  acc_create@main.c:180
                    0.00%       0ns        14       0ns       0ns       0ns  acc_delete@main.c:235
                    0.00%       0ns         3       0ns       0ns       0ns  acc_create@layers.c:176
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:242
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:400
                    0.00%       0ns        12       0ns       0ns       0ns  acc_delete@layers.c:53
                    0.00%       0ns         3       0ns       0ns       0ns  acc_alloc@layers.c:130
                    0.00%       0ns         2       0ns       0ns       0ns  acc_alloc@layers.c:411
                    0.00%       0ns        14       0ns       0ns       0ns  acc_alloc@main.c:180
                    0.00%       0ns         3       0ns       0ns       0ns  acc_delete@layers.c:148
                    0.00%       0ns         3       0ns       0ns       0ns  acc_create@layers.c:242
                    0.00%       0ns         2       0ns       0ns       0ns  acc_create@layers.c:400
```
### NV_ACC

```
$ ./cnn-cifar10 
Parallel Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.688947 seconds
CUPTI ERROR: cuptiActivityEnable(CUPTI_ACTIVITY_KIND_KERNEL) returned: CUPTI_ERROR_INSUFFICIENT_PRIVILEGES, 
         at ../../src-cupti/prof_cuda_cupti.c:338.
Create Network time:0.319131 seconds
Load Network Parameters time:0.008489 seconds
Create Ouputs time:0.000360 seconds

Net Forward total time:15.511814 seconds
    Time for conv1: 2.647081 seconds
    Time for relu1: 0.960504 seconds
    Time for pool1: 0.955713 seconds
    Time for conv2: 2.416589 seconds
    Time for relu2: 0.957380 seconds
    Time for pool2: 0.834226 seconds
    Time for conv3: 1.936767 seconds
    Time for relu3: 0.954196 seconds
    Time for pool3: 0.809971 seconds
    Time for fc: 0.841522 seconds
    Time for softmax: 2.179321 seconds

  Conv: 7.000437 seconds
  ReLU: 2.872080 seconds
  Pool: 2.599910 seconds
  FC:   0.841522 seconds
  Softmax: 2.179321 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000728 seconds
Free memory time:0.048916 seconds
Total time:16.578386 seconds
END!

Accelerator Kernel Timing data
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  make_conv_layer  NVIDIA  devicenum=0
    time(us): 279
    42: data region reached 9 times
        42: data copyin transfers: 24
             device time(us): total=279 max=34 min=4 avg=11
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  free_conv  NVIDIA  devicenum=0
    time(us): 137
    53: data region reached 9 times
        53: data copyin transfers: 18
             device time(us): total=137 max=13 min=3 avg=7
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  pad_input  NVIDIA  devicenum=0
    time(us): 0
    60: compute region reached 150000 times
        60: kernel launched 150000 times
            grid: [2560]  block: [32]
            elapsed time(us): total=2,284,402 max=409 min=14 avg=15
    60: data region reached 300000 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  conv_forward  NVIDIA  devicenum=0
    time(us): 0
    81: compute region reached 150000 times
        81: kernel launched 150000 times
            grid: [640]  block: [32x4]
            elapsed time(us): total=3,701,011 max=1,968 min=16 avg=24
    81: data region reached 300000 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  make_relu_layer  NVIDIA  devicenum=0
    time(us): 28
    130: data region reached 3 times
        130: data copyin transfers: 3
             device time(us): total=28 max=20 min=4 avg=9
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  relu_forward  NVIDIA  devicenum=0
    time(us): 0
    135: compute region reached 150000 times
        135: kernel launched 150000 times
            grid: [2560]  block: [32]
            elapsed time(us): total=2,287,813 max=357 min=14 avg=15
    135: data region reached 300000 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  free_relu  NVIDIA  devicenum=0
    time(us): 0
    148: data region reached 3 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  make_pool_layer  NVIDIA  devicenum=0
    time(us): 12
    176: data region reached 3 times
        176: data copyin transfers: 3
             device time(us): total=12 max=4 min=4 avg=4
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  pool_forward  NVIDIA  devicenum=0
    time(us): 0
    181: compute region reached 150000 times
        181: kernel launched 150000 times
            grid: [80-1024]  block: [32x4]
            elapsed time(us): total=2,053,839 max=328 min=12 avg=13
    181: data region reached 300000 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  free_pool  NVIDIA  devicenum=0
    time(us): 0
    212: data region reached 3 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  make_fc_layer  NVIDIA  devicenum=0
    time(us): 38
    242: data region reached 3 times
        242: data copyin transfers: 5
             device time(us): total=38 max=13 min=4 avg=7
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  fc_forward  NVIDIA  devicenum=0
    time(us): 0
    247: compute region reached 50000 times
        247: kernel launched 50000 times
            grid: [960]  block: [32x4]
            elapsed time(us): total=648,283 max=36 min=12 avg=12
    247: data region reached 100000 times
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  free_fc  NVIDIA  devicenum=0
    time(us): 56
    273: data region reached 3 times
        273: data copyin transfers: 4
             device time(us): total=56 max=25 min=4 avg=14
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  load_conv  NVIDIA  devicenum=0
    time(us): 56
    322: update directive reached 3 times
        322: data copyin transfers: 6
             device time(us): total=56 max=21 min=3 avg=9
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  load_fc  NVIDIA  devicenum=0
    time(us): 13
    373: update directive reached 1 time
        373: data copyin transfers: 2
             device time(us): total=13 max=9 min=4 avg=6
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  make_softmax_layer  NVIDIA  devicenum=0
    time(us): 22
    400: data region reached 2 times
        400: data copyin transfers: 3
             device time(us): total=22 max=14 min=3 avg=7
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  softmax_forward  NVIDIA  devicenum=0
    time(us): 0
    411: compute region reached 50000 times
        411: kernel launched 50000 times
            grid: [1]  block: [32]
            elapsed time(us): total=602,971 max=33 min=11 avg=12
    411: data region reached 100000 times
    418: compute region reached 50000 times
        418: kernel launched 50000 times
            grid: [1]  block: [32]
            elapsed time(us): total=612,406 max=309 min=11 avg=12
    426: compute region reached 50000 times
        426: kernel launched 50000 times
            grid: [1]  block: [32]
            elapsed time(us): total=576,327 max=3,876 min=10 avg=11
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/layers.c
  free_softmax  NVIDIA  devicenum=0
    time(us): 46
    444: data region reached 2 times
        444: data copyin transfers: 2
             device time(us): total=46 max=27 min=19 avg=23
/home/olia/Diplomatiki/cnn-cifar10_0/serial2parallel-4/main.c
  main  NVIDIA  devicenum=0
    time(us): 139,912
    180: data region reached 5 times
        44: kernel launched 2 times
            grid: [391]  block: [128]
            elapsed time(us): total=63 max=39 min=24 avg=31
        180: data copyin transfers: 1
             device time(us): total=137,933 max=137,933 min=137,933 avg=137,933
    235: data region reached 5 times
        235: data copyout transfers: 1
             device time(us): total=1,979 max=1,979 min=1,979 avg=1,979
```