# Kernels construct, managed
## Code
```c
46: void conv_forward(float* restrict X, Conv_Layer* l, float* restrict Y) {
  
    // For each output feature map
  #pragma acc kernels 
  {
    for (int m = 0; m < l->out_depth; m++) {
      for (int j = 0; j < l->out_height; j++) {
        for (int i = 0; i < l->out_width; i++) {
          int y_idx = i + (l->out_width * (j + m * l->out_height)); 
          // Calculate dot product of Weights*Input
          float sum = 0.0f;
          #pragma acc loop reduction(+:sum) 
          for (int c = 0; c < l->in_depth; c++) {
            for (int f_j = 0; f_j < l->filter_width; f_j++) {
              for (int f_i = 0; f_i < l->filter_width; f_i++) {
                int f_idx = f_i + (f_j * l->filter_width) + (c + m * l->in_depth) * (l->filter_width * l->filter_width); 
                int x_j = -l->padding + j * l->stride + f_j; 
                int x_i = -l->padding + i * l->stride + f_i; 
                // If in range of image, else zero
                if (x_j >= 0 && x_i >= 0 && x_j < l->in_height && x_i < l->in_width) {
```

## -Minfo
```
$ make
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c main.c -o main.o
arr2txt:
    331, Zero trip check eliminated
arr2txt_2:
    353, Zero trip check eliminated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c layers.c -o layers.o
conv_forward:
     51, Generating implicit copy(Y[:]) [if not already present]
         Generating implicit copyin(l,X[:]) [if not already present]
     52, Loop carried dependence due to exposed use of Y prevents parallelization
         Generating NVIDIA GPU code
         52, #pragma acc loop seq
         53, #pragma acc loop seq
         54, #pragma acc loop seq
         59, #pragma acc loop vector(128) collapse(3) /* threadIdx.x */
             Generating reduction(+:sum)
         60,   /* threadIdx.x auto-collapsed */
         61,   /* threadIdx.x auto-collapsed */
     53, Loop carried dependence due to exposed use of Y prevents parallelization
     54, Loop carried dependence due to exposed use of Y prevents parallelization
     59, Loop is parallelizable
     60, Loop is parallelizable
     61, Loop is parallelizable
pool_forward:
    153, Zero trip check eliminated
fc_forward:
    208, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c malloc2D.c -o malloc2D.o
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -c timer.c -o timer.o
cpu_timer_stop:
     11, FMA (fused multiply-add) instruction(s) generated
nvc -acc=gpu -gpu=managed -Minfo=all -c11 -Wall -Wextra -march=native  -o cnn-cifar10 main.o layers.o malloc2D.o timer.o
```

## Execution
```
$ ./cnn-cifar10 
Parallel (if) Code
CNN for 50000 images
Loading input batch 1...
Loading input batch 2...
Loading input batch 3...
Loading input batch 4...
Loading input batch 5...
Load Data time:0.276901 seconds
Create Network time:0.000301 seconds
Load Network Parameters time:0.003297 seconds
Create Ouputs time:0.000266 seconds

Net Forward total time:1212.809133 seconds
    Time for conv1: 659.505084 seconds
    Time for relu1: 8.339299 seconds
    Time for pool1: 3.541356 seconds
    Time for conv2: 418.506391 seconds
    Time for relu2: 6.362949 seconds
    Time for pool2: 1.094169 seconds
    Time for conv3: 109.443641 seconds
    Time for relu3: 4.521977 seconds
    Time for pool3: 0.377222 seconds
    Time for fc: 1.093869 seconds
    Time for softmax: 0.010671 seconds

  Conv: 1187.455117 seconds
  ReLU: 19.224226 seconds
  Pool: 5.012747 seconds
  FC:   1.093869 seconds
  Softmax: 0.010671 seconds

Net Accuracy: 78.84 % 
Net Accuracy time:0.000275 seconds
Free memory time:0.016366 seconds
Total time:1213.106539 seconds
```
